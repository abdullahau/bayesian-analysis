{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook is just here to try making up some ice cream shop data.\n",
    "\n",
    "One thing I do want to generate is a dataset that invovles causal inference concepts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_tutorial.data import load_baseball\n",
    "import pandas as pd\n",
    "from pyprojroot import here\n",
    "import namegenerator\n",
    "from faker.providers import company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(here() / 'data/baseballdb/core/Batting.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "\n",
    "f = Faker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import janitor\n",
    "import numpy as np\n",
    "\n",
    "starter_data = (\n",
    "    data\n",
    "    .query(\"yearID == 2016\")\n",
    "    .select_columns([\"playerID\", \"AB\", \"H\"])\n",
    "    .rename_columns(\n",
    "        {\n",
    "            \"playerID\":\"shopname\",\n",
    "            \"AB\": \"num_customers\",  # this is the column that matters the most\n",
    "            \"H\": \"num_likes\"        # this one isn't as important, because I will be generating data.\n",
    "        }\n",
    "    )\n",
    "    .transform_column(\"shopname\", lambda dummy : namegenerator.gen())\n",
    "    .transform_column(\"shopname\", lambda x: \" \".join(x.split(\"-\")))\n",
    "    .transform_column(\"shopname\", lambda x: x.capitalize())\n",
    "    .join_apply(lambda x: x[\"num_likes\"] / x[\"num_customers\"] if x[\"num_customers\"] > 0 else np.nan, \"fraction_likes\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we are going to do now is generate values of $p$ using a presumed hierarchical model.\n",
    "\n",
    "Firstly, likes and dislikes could be correlated by their parent chain.\n",
    "(Some chains are run well, while others are not.)\n",
    "\n",
    "The distribution of shops per company is such that most of them are independent and locally-owned businesses, while a few are large chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import poisson\n",
    "\n",
    "num_chain_held_stores = poisson(50).rvs(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Was generated from the previous cell in one particular run\n",
    "num_chain_held_stores = [55, 48, 48, 54, 44, 62, 38, 58]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 8 \"chains\", and they each have the aforementioned number of stores per chain. (Some healthy competition going on there!) For the purposes of generating data, there is a 9th \"chain\" is really just a placeholder.\n",
    "\n",
    "Let's now build the index that maps store to chain (or independent business).\n",
    "\n",
    "To do this, we will work in two steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "owner_indices = []\n",
    "# Firstly, populate chain indices.\n",
    "for i, n in enumerate(num_chain_held_stores):\n",
    "    owner_indices.extend([i] * n)\n",
    "\n",
    "# # Secondly, populate independently-owned businesses' indices.\n",
    "# for i in range(len(starter_data) - sum(num_chain_held_stores)):\n",
    "#     owner_indices.append(i + len(num_chain_held_stores))\n",
    "owner_indices.extend([i + 1] * (len(starter_data) - sum(num_chain_held_stores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we shuffle them up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "shuffle(owner_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starter_data.add_column(\"owner_idx\", owner_indices).shuffle(reset_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to generate the $p$ for each of the shops.\n",
    "\n",
    "Firstly, I'm going to start with a hard-coded population parameter. Most of the shops _are_ going to have a generally positive rating at about 0.7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_pop = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to go into logit space because it allows us to _more easily_\n",
    "reason about \"central tendencies\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import logit, expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expit(logit(p_pop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because there are 8 stores, I will generate a $p$ for each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "logit(beta(13, 17).rvs(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta(35, 8).rvs(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_ps = [\n",
    "    0.48427595,  # chain 0\n",
    "    0.52588245,  # chain 1\n",
    "    0.34491850,  # chain 2\n",
    "    0.30949678,  # chain 3\n",
    "    0.43965704,  # chain 4\n",
    "    0.31991239,  # chain 5\n",
    "    0.80628789,  # chain 6\n",
    "    0.78982137,  # chain 7\n",
    "    0.86220633,  # independent chains\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_mus = logit(company_ps)\n",
    "company_mus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import expon\n",
    "\n",
    "expon(1/4).rvs(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_sigmas = np.array([\n",
    "    0.21505173,  # chain 0\n",
    "    0.60319852,  # chain 1\n",
    "    0.30978955,  # chain 2\n",
    "    0.16837932,  # chain 3\n",
    "    0.14264645,  # chain 4\n",
    "    0.54077756,  # chain 5\n",
    "    0.18131425,  # chain 6\n",
    "    0.16748833,  # chain 7\n",
    "    1.20746328,  # independently-held businesses\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can start drawing numbers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = starter_data.add_column(\"owner_idx\", owner_indices)\n",
    "data_generator.shuffle(reset_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(company_mus) == len(company_sigmas), print(len(company_mus), len(company_sigmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_logit_p = norm(loc=company_mus, scale=company_sigmas)\n",
    "company_logit_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom \n",
    "(\n",
    "    data_generator\n",
    "    .add_column(\"mus\", company_mus[data_generator[\"owner_idx\"]])\n",
    "    .add_column(\"sigmas\", company_sigmas[data_generator[\"owner_idx\"]])\n",
    "    .join_apply(lambda x: norm(x[\"mus\"], x[\"sigmas\"]).rvs(), \"logit_p\")\n",
    "    .join_apply(lambda x: binom(x[\"num_customers\"], expit(x[\"logit_p\"])).rvs(), \"num_favs\")\n",
    ").to_csv(here() / \"data/ice_cream_shop.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesian-modelling-tutorial",
   "language": "python",
   "name": "bayesian-modelling-tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
