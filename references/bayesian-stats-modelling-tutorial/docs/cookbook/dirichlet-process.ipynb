{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook, we are going to walk through modelling situations\n",
    "that involve some form of \"cluster identification\",\n",
    "where the number of clusters isn't exactly known beforehand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chinese Restaurant Process\n",
    "\n",
    "First customer always chooses the first table.\n",
    "\n",
    "The $n$th customers afterwards occupy the first _unoccupied_ table\n",
    "with probability $\\frac{\\alpha}{n-1+\\alpha}$,\n",
    "and occupies an _already occupied_ table\n",
    "with probability $\\frac{c}{n-1+\\alpha}$.\n",
    "\n",
    "Here:\n",
    "\n",
    "- $n$ is the index of the customers after the first.\n",
    "- $c$ is the number of people already sitting at that table.\n",
    "- $\\alpha$ is a parameter of the Chinese Restaurant Process.\n",
    "\n",
    "## Let's simulate this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as np\n",
    "from jax import jit\n",
    "from jax.ops import index_update, index\n",
    "\n",
    "\n",
    "\n",
    "def create_alpha_vector(alpha, table_assignments, n, current_open_table):\n",
    "    v = np.zeros_like(table_assignments)\n",
    "    v = index_update(v, index[current_open_table], alpha)\n",
    "    return v / (n - 1 + alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_assignments = np.zeros(shape=(10,))\n",
    "table_assignments = index_update(table_assignments, index[0], 1)\n",
    "\n",
    "create_alpha_vector(5, table_assignments, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_occupied_vector(alpha, table_assignments, n, current_open_table):\n",
    "    v = table_assignments / (n - 1 + alpha)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_occupied_vector(5, table_assignments, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_assignments = np.zeros(shape=(10,))\n",
    "\n",
    "table_assignments = index_update(table_assignments, index[0], 1)\n",
    "\n",
    "np.min(np.where(table_assignments == 0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.scipy.special import logit\n",
    "from jax import vmap, lax, jit\n",
    "from jax.random import categorical, PRNGKey, split\n",
    "\n",
    "p = np.array([0.1, 0.8, 0.1])\n",
    "logit_p = np.log(p / (1 -p))\n",
    "categorical(k, logit_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = PRNGKey(42)\n",
    "\n",
    "def one_draw(k, p, zeros):\n",
    "    logits = logit(p)\n",
    "    idx = categorical(k, logits)\n",
    "    draw = index_update(zeros, index[idx], 1)\n",
    "    return draw\n",
    "\n",
    "def f(carry, x):\n",
    "    k, p = carry\n",
    "    # x is our zeros\n",
    "    draw = one_draw(k, p, x)\n",
    "    k, _ = split(k)\n",
    "    return (k, p), draw\n",
    "\n",
    "def multinomial(k, n, p):\n",
    "    n_draws = 10000\n",
    "    a = np.zeros(shape=(n_draws, len(p)))\n",
    "    (k, p), draws = lax.scan(f, (k, p), a)\n",
    "    return np.sum(draws, axis=0)\n",
    "\n",
    "multinomial(k, n=1000, p=np.array([0.3, 0.3, 0.4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draws = multinomial(k, n=1000, p=np.array([0.3, 0.3, 0.4]))\n",
    "draws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as onp\n",
    "from tqdm import tqdm\n",
    "\n",
    "alpha = 3\n",
    "table_assignments = np.zeros(shape=(alpha * 10,))\n",
    "table_assignments = index_update(table_assignments, index[0], 1)\n",
    "\n",
    "current_open_table = np.min(np.where(table_assignments == 0)[0])\n",
    "n_customers = 1000\n",
    "for n in tqdm(range(2, n_customers+1)):\n",
    "    prob_vect = create_alpha_vector(alpha, table_assignments, n, current_open_table) + create_occupied_vector(alpha, table_assignments, n, current_open_table)\n",
    "    assignment_vect = one_draw(k, prob_vect, np.zeros_like(prob_vect))\n",
    "    table_assignments = np.squeeze(table_assignments + assignment_vect)\n",
    "    current_open_table = np.min(np.where(table_assignments == 0)[0])\n",
    "    k, _ = split(k)\n",
    "prob_vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stick-breaking process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import numpy as onp\n",
    "\n",
    "# Taken from https://stats.stackexchange.com/questions/396315/coding-a-simple-stick-breaking-process-in-python\n",
    "\n",
    "def stick_breaking(k, num_weights, alpha):\n",
    "    k, _ = split(k)\n",
    "    betas = onp.random.beta(1,alpha, size=(num_weights,)) \n",
    "    betas[1:] *= onp.cumprod(1 - betas[:-1])\n",
    "    return betas\n",
    "\n",
    "\n",
    "stick_breaking(k, num_weights=max_num_classes, alpha=3).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "k, _ = split(k)\n",
    "max_num_classes = 30\n",
    "\n",
    "def stick_breaking_jax(k, num_weights, alpha):\n",
    "    k, _ = split(k)\n",
    "    betas = jax.random.beta(k, a=1, b=alpha, shape=(num_weights,))\n",
    "    products = np.cumprod(1 - betas[:-1])\n",
    "    betas = index_update(betas, index[1:], products * betas[1:])\n",
    "    return betas\n",
    "\n",
    "\n",
    "weights = stick_breaking_jax(k, num_weights=max_num_classes, alpha=2)\n",
    "plt.plot(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $\\alpha$ parameter is proportional to the number of components that we end up using."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate mixture gaussian from weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.random import categorical\n",
    "from jax.scipy.special import logit\n",
    "\n",
    "k, _ = split(k)\n",
    "n_observations = 300\n",
    "indices = categorical(k, logit(weights), shape=(n_observations,))\n",
    "indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$X \\sim N(\\mu, \\sigma)$ is equivalent to:\n",
    "\n",
    "$$ \\hat{X} \\sim N(0, 1) $$\n",
    "$$ X = \\sigma\\hat{X} + \\mu$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.random import normal\n",
    "\n",
    "mus = np.linspace(0, 350, num=max_num_classes)\n",
    "sigmas = np.ones(shape=(max_num_classes)) * 2\n",
    "mus[indices] + sigmas[indices] * normal(k, shape=(n_observations,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dp_mixture_gaussian(k, alpha, max_num_classes, num_observations, mus, sigmas):\n",
    "    weights = stick_breaking_jax(k, num_weights=max_num_classes, alpha=alpha)\n",
    "    indices = categorical(k, logit(weights), shape=(n_observations,))\n",
    "    return mus[indices] + sigmas[indices] * normal(k, shape=(n_observations,))\n",
    "\n",
    "mus = np.linspace(0, 350, num=max_num_classes)\n",
    "sigmas = np.ones(shape=(max_num_classes))\n",
    "\n",
    "draws = dp_mixture_gaussian(k, alpha=0.7, max_num_classes=45, num_observations=100, mus=mus, sigmas=sigmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(draws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecdf_scatter(data):\n",
    "    x, y = np.sort(data), np.arange(1, len(data)+1) / len(data)\n",
    "    plt.scatter(x, y)\n",
    "    plt.show()\n",
    "    \n",
    "ecdf_scatter(draws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Multiple MvNormals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import random as npr\n",
    "\n",
    "k, _ = split(k)\n",
    "draws = npr.multivariate_normal(k, mean=np.array([1, 3]), cov=np.array([[1, 0.8], [0.8, 1]]), shape=(30,))\n",
    "draws.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_spd_matrix\n",
    "max_num_classes = 45\n",
    "num_states = 2\n",
    "means = np.linspace(0, 1000, max_num_classes * num_states).reshape(max_num_classes, num_states)\n",
    "cov = np.stack([make_spd_matrix(num_states) for i in range(max_num_classes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1\n",
    "n_observations = 300\n",
    "k, _ = split(k)\n",
    "weights = stick_breaking_jax(k, num_weights=max_num_classes, alpha=alpha)\n",
    "indices = categorical(k, logit(weights), shape=(n_observations,))\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def generate_mvnorm_func(means, covs):\n",
    "    def mvnorm(key, idx):\n",
    "        k, _ = split(key)\n",
    "        return npr.multivariate_normal(k, mean=means[idx], cov=cov[idx])\n",
    "    return mvnorm\n",
    "k = PRNGKey(42)\n",
    "\n",
    "ks = []\n",
    "for i in range(n_observations):\n",
    "    k, _ = split(k)\n",
    "    ks.append(k)\n",
    "ks = np.vstack(ks)\n",
    "print(ks.shape)\n",
    "\n",
    "mvnorm = generate_mvnorm_func(means, cov)\n",
    "draws = vmap(mvnorm)(ks, indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate some data now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.random import multivariate_normal\n",
    "mus = np.array(\n",
    "    [\n",
    "        [-10, 3],\n",
    "        [5, 5],\n",
    "        [10, 1],\n",
    "    ]\n",
    ")\n",
    "# plt.scatter(mus[:, 0], mus[:, 1])\n",
    "\n",
    "covs = np.stack([make_spd_matrix(n_dim=2) for i in range(3)])\n",
    "\n",
    "k, _ = split(k)\n",
    "\n",
    "ks = []\n",
    "for i in range(150):\n",
    "    k, _ = split(k)\n",
    "    ks.append(k)\n",
    "ks = np.vstack(ks)\n",
    "\n",
    "indices = np.array([0] * 50 + [1] * 50 + [2] * 50)\n",
    "\n",
    "mvnorm = generate_mvnorm_func(mus, covs)\n",
    "draws = vmap(mvnorm)(ks, indices)\n",
    "draws.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(draws[:, 0], draws[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    # Mus should be Guassian priors of shape (max_num_components, 2)\n",
    "    mus = pm.Normal(\"mus\", mu=0, sigma=5, shape=(max_num_components, 2))\n",
    "    covs = pm.LKJCholeskyCov(\"covs\", )\n",
    "    \n",
    "    # MvNormal component distributions that we can index into.\n",
    "    comp_dists = pm.MvNormal.dist(mu=mus, cov=covs, shape=(max_num_components, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as onp\n",
    "mu = onp.zeros(3)\n",
    "true_cov = onp.array([[1.0, 0.5, 0.1],\n",
    "                     [0.5, 2.0, 0.2],\n",
    "                     [0.1, 0.2, 1.0]])\n",
    "data = onp.random.multivariate_normal(mu, true_cov, 10)\n",
    "\n",
    "with pm.Model() as model:\n",
    "    sd_dist = pm.HalfCauchy.dist(beta=2.5, shape=3)\n",
    "    chol_packed = pm.LKJCholeskyCov('chol_packed',\n",
    "        n=3, eta=2, sd_dist=sd_dist)\n",
    "    chol = pm.expand_packed_triangular(3, chol_packed)\n",
    "    vals = pm.MvNormal.dist(mu=mu, chol=chol, observed=data)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    trace = pm.sample(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "\n",
    "\n",
    "az.plot_trace(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stick_breaking(beta):\n",
    "    portion_remaining = tt.concatenate([[1], tt.extra_ops.cumprod(1 - beta)[:-1]])\n",
    "\n",
    "    return beta * portion_remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesian-modelling-tutorial",
   "language": "python",
   "name": "bayesian-modelling-tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
