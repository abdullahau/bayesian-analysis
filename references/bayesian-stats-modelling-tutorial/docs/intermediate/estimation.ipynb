{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this chapter, we are going to build off your newfound PyMC3 knowledge to build larger estimation models!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap\n",
    "\n",
    "In the previous chapter, you saw how we can use PyMC3\n",
    "to infer, or estimate, the most likely set of values of parameters of a model.\n",
    "\n",
    "- You defined a probabilistic model with key parameters of interest.\n",
    "- You used the PyMC3 Inference Button (tm), which is called using `pm.sample(n_mcmc_steps)`.\n",
    "\n",
    "\"Inference\", just so we are clear, is not \"forward\" prediction of a model. \n",
    "In statistics, it refers to the activity of ***estimating*** the most likely value of a parameter, given the data and model.\n",
    "In _Bayesian_ statistics, it refers to the activity of estimating the most likely **set** of parameters,\n",
    "given the data and model. (The \"jargon\" term here is the \"typical set\".)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Estimation\n",
    "\n",
    "Last chapter, you saw how to do \"single estimation\",\n",
    "i.e. when there's only one collection of data points\n",
    "on which we need to perform estimation.\n",
    "\n",
    "In this chapter, we are going to learn\n",
    "how to extend PyMC3 estimation code\n",
    "to handle the case where we have\n",
    "two or more groups\n",
    "that we need to perform parameter estimation for.\n",
    "Everything that you learned in the previous chapter will come in handy here!\n",
    "Let's get going!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I scream, you scream, we want ice cream!\n",
    "\n",
    "We're going to take the classic coin flip problem\n",
    "and put a different spin on it.\n",
    "\n",
    "We've got some ice cream shop data!\n",
    "In here, we have multiple ice cream shops,\n",
    "and customers are leaving either \"thumbs up\"\n",
    "or \"thumbs down\" ratings\n",
    "on whether they enjoyed the ice cream shop experience.\n",
    "The problem task we have at hand\n",
    "is to rank order the shops\n",
    "according to their customer experience rating.\n",
    "\n",
    "This example is going to be the pedagogical one that we work through\n",
    "over the this chapter and the next (when we discuss hierarchical models).\n",
    "Other examples and exercises will be available\n",
    "to help you get practice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data\n",
    "\n",
    "Let's load in the data and take a quick look at it\n",
    "to make sure we know what we're dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyprojroot import here\n",
    "import janitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_tutorial.data import load_ice_cream\n",
    "\n",
    "data = load_ice_cream()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a description of the columns:\n",
    "\n",
    "- `shopname`: A string identifier for the shop.\n",
    "- `num_customers`: The number of customers that responded to a survey about whether they liked or didn't like the shopping experience.\n",
    "- `owner_idx`: A numerical index of the holding company for a bunch of stores. Indices 0-7 are multi-store chains, while index 8 is a \"catch-all\" index for the stores that are independently and locally owned.\n",
    "- `num_favs`: This is the observed number of likes in the responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical pitfalls\n",
    "\n",
    "At first glance, the task of estimating how \"good\" a shop is\n",
    "might sound like an easy task:\n",
    "_Just_ calculate:\n",
    "\n",
    "$$\\hat{p} = \\frac{n_{favs}}{n_{customers}}$$\n",
    "\n",
    "Apparently, if we treat this \"proportion of likes\"\n",
    "as a surrogate measure of the likeability of a store, \n",
    "this should give us an intrinsic measure of how good the store is.\n",
    "\n",
    "Right??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "We're going to see how that could be a difficult thing to justify.\n",
    "\n",
    "Add a new column to the dataframe that adds a naive estimation of $p$, i.e. $\\hat{p}$, for each store.\n",
    "\n",
    "Some hints:\n",
    "\n",
    "- You are _definitely_ going to worry about the case where `num_customers = 0`, and come up with a principled solution for that.\n",
    "    - Your two choices, basically, are to call it 0, or call it some `null` type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import janitor\n",
    "import numpy as np\n",
    "\n",
    "from bayes_tutorial.solutions.estimation import naive_estimate\n",
    "\n",
    "# My answer:\n",
    "estimated_p = naive_estimate(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your dataframe should look something like this.\n",
    "estimated_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "If you chose `0` as the calculated value of $\\hat{p}$ when `num_customers = 0`,\n",
    "what might you have to be careful about later on?\n",
    "\n",
    "If you chose `np.nan` (or some other equivalent `null` representation)\n",
    "as your calculated value of $\\hat{p}$ when `num_customers = 0`,\n",
    "what might you have to be careful about later on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put in your answer in between the triple quotes below.\n",
    "ans = \"\"\"\n",
    "Your answer here.\n",
    "\"\"\"\n",
    "\n",
    "# My answer is below. Uncomment to read it, or read it at the end.\n",
    "from bayes_tutorial.solutions.estimation import assumptions\n",
    "\n",
    "# print(assumptions())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing Two-Group Estimation Models\n",
    "\n",
    "To illustrate how to progress from \"one group estimation\" to \"multi-group estimation\",\n",
    "we are going to stop by two-group estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-group estimation\n",
    "\n",
    "To construct a so-called one-group estimation model,\n",
    "let's build a $p$ estimation model for one of the stores,\n",
    "say, \"Gimpy periwinkle bombay\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_data = estimated_p.query(\"shopname == 'Gimpy periwinkle bombay'\")\n",
    "store_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model\n",
    "\n",
    "Remember the protocol for building models:\n",
    "start from a good likelihood distribution that describes the observed data,\n",
    "and work backwards to the key parameters of interest.\n",
    "The best distribution story for the sum of 1/0 trials\n",
    "is the Binomial distribution.\n",
    "It takes in two parameters, `n` and `p`.\n",
    "`n` is known in the data,\n",
    "but `p` is the intrinsic property\n",
    "that we are trying to model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "\n",
    "with pm.Model() as one_group_model:\n",
    "    p = pm.Beta(\"p\", alpha=2, beta=2)\n",
    "    like = pm.Binomial(\n",
    "        \"like\",\n",
    "        n=store_data[\"num_customers\"],\n",
    "        p=p,\n",
    "        observed=store_data[\"num_favs\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In graphical form, this model looks like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_tutorial.solutions.estimation import ice_cream_one_group_pgm\n",
    "\n",
    "ice_cream_one_group_pgm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample from Posterior\n",
    "\n",
    "Now, we can hit the inference button!\n",
    "\n",
    "(It helps to give the trace object an informative name though,\n",
    "so let's call it something other than a generic `trace`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with one_group_model:\n",
    "    trace_one_group = pm.sample(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Posterior Distribution\n",
    "\n",
    "Let's now visualize the posterior distribution of `p`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "\n",
    "az.plot_posterior(trace_one_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model\n",
    "\n",
    "Now, let's build the two-group version of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "\n",
    "wanted_stores = [\"Crabby smalt walrus\", \"Gimpy periwinkle bombay\"]\n",
    "two_store_data = estimated_p.query(\"shopname in @wanted_stores\")\n",
    "\n",
    "with pm.Model() as two_group_model:\n",
    "    p = pm.Beta(\"p\", alpha=2, beta=2, shape=(len(two_store_data),))\n",
    "    like = pm.Binomial(\"like\", n=two_store_data[\"num_customers\"], p=p, observed=two_store_data[\"num_favs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key here is to express the \"sample dimension\" in the shape of the `p` random variable.\n",
    "\n",
    "As a graphical model, this model looks like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_tutorial.solutions.estimation import ice_cream_n_group_pgm\n",
    "\n",
    "ice_cream_n_group_pgm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new thing that might look different from what you've seen before thus far\n",
    "is the rectangle box.\n",
    "This is known as a _plate_.\n",
    "The _plate_ indicates that there's a \"cloning\" of the random variables.\n",
    "Instead of one `p` and one `likes`, there are `n_shops` times as many."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample from Posterior\n",
    "\n",
    "Now, let's use the PyMC3 Inference Button (tm) to sample from the joint posterior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "\n",
    "with two_group_model:\n",
    "    trace_two_group = pm.sample(2000)\n",
    "    trace_two_group = az.from_pymc3(\n",
    "        trace_two_group,\n",
    "        coords={\"p_dim_0\": two_store_data[\"shopname\"]}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A convention to remember here: When you have an RV that has a shape axis, ArviZ will automatically append a `_dim_0` to the end of it in the resulting xarray coordinate system.\n",
    "\n",
    "As such, if you want to conveniently guarantee that the store labels (the true coordinates) are displayed in the posterior distribution plots, you must pass them in when converting the trace from a PyMC3 trace object into an ArviZ `InferenceData` object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Posterior Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(trace_two_group);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forest Plot\n",
    "\n",
    "The \"forest plot\" is a _compact_ visual representation of posterior distributions.\n",
    "Let's take a look at how to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_forest(trace_two_group);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting forest plots\n",
    "\n",
    "- The circle is the median\n",
    "- The thick bars indicate the inter-quartile range\n",
    "- The thin bars indicate the 94th percentile range (3-97)\n",
    "- There are four bars because each of them indicate one MCMC chain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting in context of the problem\n",
    "\n",
    "Our goal here was to rank-order the stores.\n",
    "\n",
    "With the model, we can rank-order the stores according to quantiles of the posterior distribution.\n",
    "\n",
    "- By the median, the store Crabby smalt walrus is better than the Gimpy periwinkle bombay store.\n",
    "- By the uppper bound (97th percentile), the same holds.\n",
    "- By the lower-bound (3rd percentile), the same still holds.\n",
    "\n",
    "Hence, we should be quite confident that Crabby smalt walrus >> Gimpy periwinkle bombay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability of Superiority\n",
    "\n",
    "Another approach that we can take to comparing two stores\n",
    "is to calculate the \"probability of superiority\" of one store over the other.\n",
    "Given samples from the posterior distribution, this is trivial to calculate.\n",
    "Over all pairs of samples taken, we simply have to ask\n",
    "in what fraction of samples does one store have a higher `p` than the other.\n",
    "\n",
    "This is a pretty useful way of directly comparing two posterior distributions to one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store1 = trace_two_group.posterior.stack(dimensions={\"draws\": (\"chain\", \"draw\")})[\"p\"].sel(p_dim_0=\"Gimpy periwinkle bombay\")\n",
    "store2 = trace_two_group.posterior.stack(dimensions={\"draws\": (\"chain\", \"draw\")})[\"p\"].sel(p_dim_0=\"Crabby smalt walrus\")\n",
    "\n",
    "np.sum(store1 > store2) / len(store1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the probability that the store \"Gimpy periwinkle bombay\" is better than \"Crabby smalt walrus\" is basically nothing.\n",
    "This same pattern shows up in the forest plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Extend the model to 4 stores\n",
    "\n",
    "We're now going to build a model that can handle more than just two stores, but an arbitrary number of stores.\n",
    "\n",
    "In order to test-drive the construction of the estimation model,\n",
    "we are going to start by ensuring that the model works on just four stores,\n",
    "but you should write it in such a way that it can work with _any_ number of stores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wanted_stores = [\n",
    "    \"Crabby smalt walrus\",\n",
    "    \"Gimpy periwinkle bombay\",\n",
    "    \"Beady razzmatazz jaguar\",\n",
    "    \"Snazzy auburn skunk\"\n",
    "]\n",
    "\n",
    "four_store_data = estimated_p.query(\"shopname in @wanted_stores\")\n",
    "four_store_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "four_store_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ice_cream_store_model(data: pd.DataFrame) -> pm.Model:\n",
    "    with pm.Model() as model:\n",
    "        # Your answer here.\n",
    "        pass\n",
    "    return model\n",
    "\n",
    "from bayes_tutorial.solutions.estimation import ice_cream_store_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ice_cream_store_model(four_store_data):\n",
    "    trace_four_store = pm.sample(2000)\n",
    "    trace_four_store = az.from_pymc3(trace_four_store, coords={\"p_dim_0\": four_store_data[\"shopname\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_forest(trace_four_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation in context\n",
    "\n",
    "If you remember the data, the store _Snazzy auburn skunk_ had a rating of 1 like out of 1 response.\n",
    "On a naive, point estimate, 1.0 would be its score for `p`,\n",
    "but we would probably be left being quite dissatisfied with ranking it first.\n",
    "After all, there is (qualitatively speaking) very little information available in 1 vote.\n",
    "\n",
    "With a Bayesian posterior, we now would rank _Snazzy auburn skunk_ in 3rd place according to the median and 3rd percentile,\n",
    "and 2nd place according to the upper bound 97th percentile of the posterior.\n",
    "Already, the benefits of a Bayesian approach to rank-ordering stores is visible:\n",
    "in this particular case, a weakly informative prior distribution helped us regulate the posterior estimates\n",
    "(this is called \"regularization\")\n",
    "away from extreme values.\n",
    "\n",
    "The posterior distribution width also quantitatively describes how uncertain we are;\n",
    "**the larger the width of the posterior distribution, the greater the uncertainty.**\n",
    "This is something worth keeping in mind!\n",
    "\n",
    "\n",
    "_A microbiome professionals might chime in and remind us to analyze our posteriors -- they're very informative!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Probability of superiority\n",
    "\n",
    "Calculate the probability of superiority of Gimpy periwinkle bombay over Snazzy auburn skunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store1 = trace_four_store.posterior.stack(dimensions={\"draws\": (\"chain\", \"draw\")})[\"p\"].sel(p_dim_0=\"Gimpy periwinkle bombay\")\n",
    "store2 = trace_four_store.posterior.stack(dimensions={\"draws\": (\"chain\", \"draw\")})[\"p\"].sel(p_dim_0=\"Snazzy auburn skunk\")\n",
    "\n",
    "np.sum(store1 > store2) / len(store1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the posterior distributions, Gimpy periwinkle bombay has about a 90% probability of superiority over Snazzy auburn skunk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Exercise\n",
    "\n",
    "Write a function that takes in the posterior distribution trace\n",
    "and returns a pandas DataFrame with their $k^{th}$ percentiles,\n",
    "which we can rank-order after-the-fact. \n",
    "(i.e. don't return ranks!)\n",
    "\n",
    "Some hints:\n",
    "\n",
    "- You might need to be familiar with `xarray`'s API in order to work through this problem.\n",
    "- The class methods that you are interested in are probably `stack` and `quantile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_tutorial.solutions.estimation import posterior_quantile\n",
    "\n",
    "quantiles = posterior_quantile(trace_four_store, q=[0.03, 0.5, 0.97])\n",
    "quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles.unstack().rank()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank-order all stores\n",
    "\n",
    "Now that you've built a model that can generalize across multiple samples,\n",
    "I'd like to invite you to go ahead and rank-order all stores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from posterior of model that knows about all stores.\n",
    "\n",
    "# Your answer below:\n",
    "\n",
    "\n",
    "# The \"correct\" answer is here:\n",
    "from bayes_tutorial.solutions.estimation import trace_all_stores\n",
    "trace = trace_all_stores(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = posterior_quantile(trace, q=[0.03, 0.5, 0.97])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on each of the quantiles, is there a clear winner?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles.unstack().rank().sort_values((\"p\", 0.97))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles.unstack().rank().sort_values((\"p\", 0.03))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this chapter, we went a little deeper into the Bayesian workflow. Here's what you've learned from this chapter.\n",
    "\n",
    "Firstly, you learned how to extend an estimation model that worked with \"single\" samples,\n",
    "to performing \"multiple estimation\", in which you estimated a key parameter for multiple samples.\n",
    "The key idea here was to learn how to use vectorized syntax.\n",
    "\n",
    "Secondly, you learned a bit of workflow.\n",
    "Before we went ahead and built a model to be fit on _all samples_,\n",
    "we built the model in such a way that it could handle _some_ of the samples.\n",
    "Only after checking that we could perform posterior sampling on _some_ of the samples\n",
    "did we then apply the model across _all_ of the samples.\n",
    "\n",
    "Thirdly, you learned how to handle summary values from the posterior distribution trace.\n",
    "This includes calculating quantiles of the posterior.\n",
    "You can calculate means, standard deviations, and more,\n",
    "but practically speaking, simple quantiles are already quite expressive.\n",
    "`xarray` syntax is something you will want to become very familiar with,\n",
    "as `xarray` provides idiomatic high-dimensional data structures\n",
    "that are useful for storing Bayesian posterior calculations.\n",
    "\n",
    "Some of the things that should have stood out here are that\n",
    "we did not make binary/discretized decisions, \n",
    "like ranking things, early on. \n",
    "Instead, we deferred them\n",
    "until the full posterior distributions were calculated.\n",
    "Only then did we try to organize what we concluded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next chapter\n",
    "\n",
    "In the next chapter, we're going to solve some of the unsatisfying parts of this model.\n",
    "In particular, if you remember some of those \"really wide\" posterior distributions\n",
    "that have a ton of uncertainty in them and can recall yourself being distinctly dissatisfied with them,\n",
    "then the next chapter might help resolve some of that lingering dissatisfaction!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesian-modelling-tutorial",
   "language": "python",
   "name": "bayesian-modelling-tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
