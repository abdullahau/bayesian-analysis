{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "What happens when we hit the Inference Button (tm)? Is it gradient descent that is happening underneath the hood? What is this \"sampler\" we speak about, and what exactly is it doing?\n",
    "\n",
    "As we take a detour away from PyMC3 for a moment,\n",
    "those fundamental questions are the questions\n",
    "that we are going to go through in this chapter.\n",
    "It's my hope that you'll enjoy peeling back the covers\n",
    "on _some_ of what happens underneath the hood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In the beginning...\n",
    "\n",
    "First off, we must remember that with Bayesian statistical inference,\n",
    "we are most concerned with computing the posterior distribution of parameters\n",
    "conditioned on data, $P(H|D)$.\n",
    "Here, $H$ refers to the parameter set and the model,\n",
    "while $D$ refers to the data.\n",
    "\n",
    "Because it is a conditional distribution,\n",
    "by invoking the rules of probability, where\n",
    "\n",
    "$$P(H,D)=P(H|D)P(D)=P(D|H)P(D)$$\n",
    "\n",
    "if you were to treat each of the $P$s as algebraic elements,\n",
    "then a simple rearrangement gives us:\n",
    "\n",
    "$$P(H|D)=\\frac{P(D|H)P(H)}{P(D)}$$\n",
    "\n",
    "This, then, is Bayes' rule as applied to joint distributions\n",
    "of data and model parameters.\n",
    "\n",
    "One hiccup shows here, though,\n",
    "in that we cannot analytically know how to calculate $P(D)$.\n",
    "The reason for this is that we don't have an analytical form\n",
    "for the probability distribution of how data could have been configured.\n",
    "In practice, we treat that as a normalizing constant,\n",
    "since philosophically, data are considered constant\n",
    "while parameters are random variables. \n",
    "Hence, our posterior distribution\n",
    "is calculated as a proportionality term:\n",
    "\n",
    "$$P(H|D) \\propto P(D|H)P(H)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at an illustration\n",
    "\n",
    "To make everything a bit more concrete, let's look at what I call\n",
    "a \"simplest complex example\",\n",
    "one that is not too hard to \"grok\" (geek slang for _understand_),\n",
    "but one that is complex enough to be interesting.\n",
    "\n",
    "We're going to inspect this particular model:\n",
    "\n",
    "\n",
    "$$\\mu_d \\sim N(\\mu=3, \\sigma=1)$$\n",
    "$$\\sigma_d \\sim Exp(\\lambda=13)$$\n",
    "$$d \\sim N(\\mu=\\mu_d, \\sigma=\\sigma_d)$$\n",
    "\n",
    "We have Gaussian-distributed data,\n",
    "where the mean of the data distribution,\n",
    "$\\mu_d$ is a Gaussian-distributed random variable\n",
    "that has a configuration that specifies our prior belief about it\n",
    "having not seen any data,\n",
    "while the variance of the data distribution,\n",
    "$\\sigma_d$ is an Exponentially-distributed random variable,\n",
    "also configured in a way that specifies our prior without having seen any data.\n",
    "\n",
    "The model's PGM looks something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from daft import PGM\n",
    "\n",
    "G = PGM()\n",
    "G.add_node(\"mu\", content=r\"$\\mu$\")\n",
    "G.add_node(\"sigma\", content=r\"$\\sigma$\", x=1)\n",
    "G.add_node(\"d\", content=\"d\", x=0.5, y=-1)\n",
    "\n",
    "G.add_edge(\"mu\", \"d\")\n",
    "G.add_edge(\"sigma\", \"d\")\n",
    "G.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Generative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generative_model():\n",
    "    mu = norm(loc=8, scale=3).rvs()\n",
    "    sigma = expon(scale=3).rvs()\n",
    "    data = norm(loc=mu, scale=sigma).rvs()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Joint log-likelihood\n",
    "\n",
    "Write down the joint log-likelihood between data and the model parameters under the pre-specified priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm, expon\n",
    "def log_like(mu, sigma, data):\n",
    "    mu_like = norm(loc=8, scale=1).logpdf(mu)\n",
    "    sigma_like = expon(scale=3).logpdf(sigma)\n",
    "    data_like = norm(loc=mu, scale=sigma).logpdf(data).sum() # sum is important!\n",
    "    return mu_like + sigma_like + data_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n):\n",
    "    for i in range(n):\n",
    "        yield generative_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I'm going to give you some _actual_ data,\n",
    "and I'd like you to propose a $\\mu$ and a $\\sigma$,\n",
    "and then evaluate their joint log-likelihood with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "true_mu = 2\n",
    "true_sigma = 1\n",
    "data = norm(true_mu, true_sigma).rvs(150)\n",
    "log_like(-2, 1, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot how the log likelihood varies with $\\mu$ and $\\sigma$.\n",
    "This will give us a great way to visualize the posterior distribution space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, FloatSlider, IntSlider\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "min_mu, max_mu = -3, 15\n",
    "mu = FloatSlider(min=min_mu, max=max_mu, value=0, step=0.1, description=r\"$\\mu$\")\n",
    "min_sigma, max_sigma = 0.1, 5\n",
    "sigma = FloatSlider(min=min_sigma, max=max_sigma, value=1, step=0.1, description=r\"$\\sigma$\")\n",
    "num_data = IntSlider(min=0, max=100, step=1, value=20, description=\"Num Data Points\")\n",
    "\n",
    "\n",
    "@interact(mu=mu, sigma=sigma, num_data=num_data)\n",
    "def plot_univariate_posterior(mu, sigma, num_data):\n",
    "    mu_range = np.linspace(min_mu, max_mu, 100)\n",
    "    sigma_range = np.linspace(min_sigma, max_sigma, 100)\n",
    "    d = data[0:num_data]\n",
    "    ll_sigma = [log_like(mu, s, d) for s in sigma_range]\n",
    "    ll_mu = [log_like(m, sigma, d) for m in mu_range]\n",
    "    fig, ax = plt.subplots(figsize=(8,4), nrows=1, ncols=2)\n",
    "    ax[0].plot(sigma_range, np.exp(ll_sigma))\n",
    "    ax[0].set_xlabel(\"$\\sigma$\")\n",
    "    ax[0].set_title(f\"$\\mu$ fixed at {mu}\")\n",
    "    ax[1].plot(mu_range, np.exp(ll_mu))\n",
    "    ax[1].set_xlabel(\"$\\mu$\")\n",
    "    ax[1].set_title(f\"$\\sigma$ fixed at {sigma}\")\n",
    "    ax[0].set_ylabel(\"log likelihood\")\n",
    "    sns.despine()\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're on the online version of this notebook, you'll have some sliders that you can play with.\n",
    "\n",
    "The first slider, $\\mu$, allows you to fix $\\mu$ at a particular value,\n",
    "while letting $\\sigma$ vary.\n",
    "The second  slider, $\\sigma$, allows you to fix $\\sigma$ at a particular value,\n",
    "while letting $\\mu$ vary.\n",
    "On the y-axis of both is the joint log likelihood of the model and data,\n",
    "but with $\\mu$ fixed with the data on the $\\sigma$ plot,\n",
    "and with $\\sigma$ fixed with the data on the $\\mu$ plot.\n",
    "\n",
    "There's a few things you might want to note.\n",
    "\n",
    "Firstly, if you set Num Data to 0, you should see the joint log likelihood with no data, a.k.a. the prior log likelihood.\n",
    "\n",
    "Secondly, the parameter sliders for $\\mu$ and $\\sigma$ will allow you to \"fix\" a parameter value.\n",
    "The plot on the left has $\\mu$ fixed, while the plot on the right has $\\sigma$ fixed.\n",
    "In both cases, the data are also fixed at what was observed.\n",
    "\n",
    "Thirdly, as you add the number of data points used to evaluate the log likelihood,\n",
    "you should see the true values of the parameters converge towards the true value,\n",
    "conditioned on you setting the \"fixed\" parameter value (using the sliders) to the true value too.\n",
    "When the \"fixed\" parameters are wrong, inference about the other parameter will be wrongn too.\n",
    "This shows the importance of _jointly_ inferring the values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling: Metropolis-Hastings\n",
    "\n",
    "An easy-to-understand sampler that we can start with\n",
    "is the Metropolis-Hastings sampler.\n",
    "I first learned it in a grad-level computational biology class,\n",
    "but I expect most statistics undergrads should have\n",
    "a good working knowledge of the algorithm.\n",
    "\n",
    "Here's how the algorithm works,\n",
    "shamelessly copied (and modified)\n",
    "from the [Wikipedia article](https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm):\n",
    "\n",
    "- For each parameter $p$, do the following.\n",
    "- Initialize an arbitrary point for the parameter (this is $p_t$, or $p$ at step $t$).\n",
    "- Define a probability density $P(p_t)$, for which we will draw new values of the parameters. Here, we will use $P(p) = Normal(p_{t-1}, 1)$.\n",
    "- For each iteration:\n",
    "    - Generate candidate new candidate $p_t$ drawn from $P(p_t)$.\n",
    "    - Calculate the likelihood of the data under the previous parameter value(s) $p_{t-1}$: $L(p_{t-1})$\n",
    "    - Calculate the likelihood of the data under the proposed parameter value(s) $p_t$: $L(p_t)$\n",
    "    - Calculate acceptance ratio $r = \\frac{L(p_t)}{L(p_{t-1})}$.\n",
    "    - Generate a new random number on the unit interval: $s \\sim U(0, 1)$.\n",
    "    - Compare $s$ to $r$.\n",
    "        - If $s \\leq r$, accept $p_t$.\n",
    "        - If $s \\gt r$, reject $p_t$ and continue sampling again with $p_{t-1}$.\n",
    "        \n",
    "Because of a desire for convenience,\n",
    "we could choose to use a normal distribution to sample all values.\n",
    "However, that distribution choice is possibly going to bite us during sampling,\n",
    "because the values that we could possibly sample for the $\\sigma$ parameter\n",
    "can take on negatives,\n",
    "but when a negative $\\sigma$ is passed\n",
    "into the normally-distributed likelihood,\n",
    "we are going to get computation errors!\n",
    "This is because the scale parameter of a normal distribution\n",
    "can only be positive, and cannot be negative or zero.\n",
    "(If it were zero, there would be no randomness.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations as a hack\n",
    "\n",
    "The key problem here is that the support of the Exponential distribution\n",
    "is bound to be positive real numbers only.\n",
    "That said, we can get around this problem\n",
    "simply by sampling amongst the unbounded real number space $(-\\inf, +\\inf)$,\n",
    "and then transforming the number by a math function to be in the bounded space.\n",
    "\n",
    "One way we can transform numbers from an unbounded space\n",
    "to a positive-bounded space\n",
    "is to use the exponential transform:\n",
    "\n",
    "$$y = e^x$$\n",
    "\n",
    "For any given value $x$, $y$ will be guaranteed to be positive.\n",
    "\n",
    "And _voila_!\n",
    "The key trick here was to **sample in unbounded space**,\n",
    "but **evalute log-likelihood in bounded space**.\n",
    "We call the \"unbounded\" space the _transformed_ space,\n",
    "while the \"bounded\" space is the _original_ or _untransformed_ space.\n",
    "We have implemented the necessary components\n",
    "to compute posterior distributions on parameters!\n",
    "\n",
    "This is something that a probabilistic programming language, such as PyMC3, will do for you,\n",
    "so you don't have to worry about transforming your random variables for sampling.\n",
    "(That said, you still have to worry about transforming your RVs for model building,\n",
    "as we have seen in the chapter on hierarchical modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting things all together\n",
    "\n",
    "Let's see how we an implement a simple MCMC sampler,\n",
    "one that uses the Metropolis-Hastings algorithm, for sampling.\n",
    "\n",
    "Follow along the block of code below:\n",
    "_look at the comments for notes on the important bits!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "##### Read the code and commennts carefully! #####\n",
    "\n",
    "# Here, we initialize our \"guesses\" for mu and sigma.\n",
    "mu_prev = np.random.normal()\n",
    "sigma_prev = np.random.normal()\n",
    "\n",
    "# Keep a history of the parameter values and ratio.\n",
    "mu_history = dict()\n",
    "sigma_history = dict()\n",
    "ratio_history = dict()\n",
    "\n",
    "for i in tqdm(range(1000)):\n",
    "    # We record the history of values on each loop.\n",
    "    mu_history[i] = mu_prev\n",
    "    sigma_history[i] = sigma_prev\n",
    "    \n",
    "    # Now, we propose new values centered on the previous values\n",
    "    mu_t = np.random.normal(mu_prev, 0.1)\n",
    "    sigma_t = np.random.normal(sigma_prev, 0.1)\n",
    "\n",
    "    # Compute joint log likelihood\n",
    "    LL_t = log_like(mu_t, np.exp(sigma_t), data)\n",
    "    # NOTE: because sigma has to be positive, we apply an exponential transform\n",
    "    LL_prev = log_like(mu_prev, np.exp(sigma_prev), data)\n",
    "\n",
    "    # Calculate the difference in log-likelihoods\n",
    "    # (or a.k.a. ratio of likelihoods)\n",
    "    diff_log_like = LL_t - LL_prev\n",
    "    if diff_log_like > 0:\n",
    "        ratio = 1\n",
    "    else:\n",
    "        # We need to exponentiate to get the correct ratio,\n",
    "        # since all of our calculations were in log-space\n",
    "        ratio = np.exp(diff_log_like)\n",
    "\n",
    "    # Defensive programming check\n",
    "    if np.isinf(ratio) or np.isnan(ratio):\n",
    "        raise ValueError(f\"LL_t: {LL_t}, LL_prev: {LL_prev}\")\n",
    "\n",
    "    # Ratio comparison step\n",
    "    ratio_history[i] = ratio\n",
    "    p = np.random.uniform(0, 1)\n",
    "    if ratio >= p:\n",
    "        mu_prev = mu_t\n",
    "        sigma_prev = sigma_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's visualize how our sampling went."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import janitor\n",
    "import pandas as pd\n",
    "\n",
    "trace = (\n",
    "    pd.DataFrame(\n",
    "        pd.Series(sigma_history, name=\"sigma\")\n",
    "    )\n",
    "    .join(\n",
    "        pd.Series(mu_history, name=\"mu\")\n",
    "    )\n",
    "    # We have to transform the sampled values into the correct space.\n",
    "    .transform_column(\"sigma\", np.exp)\n",
    ")\n",
    "\n",
    "trace.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we were able to recover the true $\\mu$ and $\\sigma$,\n",
    "as well as estimate the uncertainty around their values!\n",
    "\n",
    "Notice how it took a couple few dozenns of steps before the trace becomes **stationary**,\n",
    "that is it becomes a flat trend-line.\n",
    "If we prune the trace to just the values after the 200th iteration,\n",
    "we get the following trace:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace.loc[200:].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Important Lessons\n",
    "\n",
    "This short, short interlude should have given you\n",
    "a flavour of how MCMC sampling happens.\n",
    "Here are some of the main things that I hope you've taken away from this chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling, not optimization\n",
    "\n",
    "Note here that we didn't _optimize_ the values of $\\mu$ and $\\sigma$\n",
    "to maximize likelihood.\n",
    "Rather, we were simulating the full joint likelihood space via sampling,\n",
    "while also using the sampler to get us within the _region_ of the true values.\n",
    "With this, we are able to obtain a _distribution_ rather than a _point estimate_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log-likelihood is all you need\n",
    "\n",
    "I've written that line multiple times in this series,\n",
    "but hopeffully this time round, the reason why is clear:\n",
    "in order to use sampling to estimate the values of the parameters conditioned on data,\n",
    "we need the joint log-likelihood of our data and model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint sampling\n",
    "\n",
    "As the interactive example should have revealed,\n",
    "_jointly_ estimating the correct values is very important\n",
    "if we don't want to have biases in the estimates.\n",
    "As such, we must perform sampling on both values simultaneously,\n",
    "rather than independently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sane defaults\n",
    "\n",
    "The act of implementing a sampler is educational\n",
    "in the same way that reinventing the wheel teaches you about the wheel.\n",
    "But for a large fraction of problems,\n",
    "a custom sampler isn't necessary,\n",
    "and reimplementing them on every new problem is tedious!\n",
    "\n",
    "That's where a probabilistic programming language (PPL) steps in!\n",
    "Any probablistic programming language should provide you with\n",
    "\n",
    "1. a library of probability distributions with a uniform API,\n",
    "2. a library of MCMC samplers with also a uniform API,\n",
    "3. a method for automatically constructing a joint log-likelihood function from a model specification and data\n",
    "\n",
    "For the samplers, a well-designed PPL will provides you with _very sane defaults_\n",
    "on which sampler to use, and how they are to be configured.\n",
    "For example, in PyMC3, the No-U-Turn-Sampler,\n",
    "one that leverages the gradient of the log likelihood w.r.t. the parameters\n",
    "to help propose new values to sample,\n",
    "is the default for continuous random variables,\n",
    "because it converges in fewer steps (especially for high dimensional problems)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesian-modelling-tutorial",
   "language": "python",
   "name": "bayesian-modelling-tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
