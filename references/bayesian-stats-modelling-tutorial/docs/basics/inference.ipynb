{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this chapter, we are going to build off the knowledge you've learned in the previous chapters,\n",
    "and introduce you to the wonderful world of probabilistic inference using PyMC3!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap\n",
    "\n",
    "Let's recap what you've learned so far.\n",
    "\n",
    "Thus far, you have encountered:\n",
    "\n",
    "- The basics of probability, and how joint probability links to joint modelling between data and parameters.\n",
    "- How to simulate data generating processes, and evaluate the joint likelihood of data and parameter \"guesses\".\n",
    "\n",
    "In short, you have learned all about the so-called \"forward\" pass of modelling.\n",
    "(Take the term \"forward\" with a grain of salt, it is meant to be an idea,\n",
    "not an official term that belongs to the discipline of statistics.)\n",
    "We introduced you to the term **prior belief** as well.\n",
    "In this chapter, we will be performing _inference_, or in other words,\n",
    "taking principled guesses at what \"set\" of values of our parameters best explain our data,\n",
    "conditioned on our original hypotheses about what their values should be,\n",
    "or in other words, calculating posterior beliefs having seen the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic Modelling\n",
    "\n",
    "In simulating the data generating process with probability distributions,\n",
    "you wrote a **\"probabilistic\"** model.\n",
    "Other names for this include a \"stochastic\" model, or a \"non-deterministic\" model.\n",
    "\n",
    "In the spirit of sticking with simple complex examples, we are going to continue exploring the classic coin flip model.\n",
    "Though it might seem like the example can be beaten-to-death, stick with me,\n",
    "as it's a very useful pedagogical tool.\n",
    "Once we've graduated from the classic coin flip,\n",
    "you'll be equipped with the right abstractions to handle other models easily!\n",
    "\n",
    "Let's take that coin flip model with Beta-distributed $p$, and implement it in PyMC3 code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In mathy syntax, the model can be expressed as follows:\n",
    "\n",
    "$$ p \\sim Beta(\\alpha=2, \\beta=2)$$\n",
    "$$ Y \\sim Bernoulli(p=p)$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $Y$ is the random variable modelling coin flip results,\n",
    "- $p$ is the key parameter of the Bernoulli distribution likelihood, which is used to model the space of possibilities for $Y$,\n",
    "- and $\\alpha$ and $\\beta$ are the key parameters of the Beta distribution, which is used to model the space of possibilities for $p$. Having them set to $2$ each is a modelling decision that I have taken.\n",
    "\n",
    "To jog your memory, here's how we wrote the data generating process\n",
    "in the previous notebook using `scipy.stats`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_tutorial.solutions.simulation import coin_flip_generator_v2\n",
    "from inspect import getsource\n",
    "\n",
    "coin_flip_generator_v2??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we move on, we should also see what the state of our priors look like, having not seen any data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Plot the PDF of the prior distribution of $p$. \n",
    "\n",
    "Hints to help you along:\n",
    "\n",
    "- You'll need to access the `.pdf()` class method of the Beta distribution object.\n",
    "- Remember that the `.pdf()` function takes in `x`, on which you evaluate the PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import beta\n",
    "import numpy as np\n",
    "from bayes_tutorial.solutions.inference import plot_betadist_pdf\n",
    "\n",
    "# This is the answer below\n",
    "plot_betadist_pdf(2, 2)\n",
    "\n",
    "# Your answer below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This probability density function describes what we believe about the likelhood of $p$,\n",
    "having not seen the data.\n",
    "It is centered on 0.5, which means we generally ascribe highest likelihood to a \"fair coin\",\n",
    "but it is also wide, with quite a bit of density\n",
    "outside of the vicinity of 0.5.\n",
    "We ascribe very little likelihood at 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coin Flip in PyMC3\n",
    "\n",
    "Let's now see how we can convert this coin flip model into a PyMC3 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "\n",
    "with pm.Model() as model:\n",
    "    p = pm.Beta(\"p\", alpha=2, beta=2)\n",
    "    data = pm.Bernoulli(\"data\", p=p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like that, we have specified a probabilistic model for coin flips!\n",
    "Notice how, first of all, the syntax matches very closely\n",
    "to how the probabilistic model is written in traditional math syntax,\n",
    "as well as the `scipy.stats` syntax.\n",
    "In particular,\n",
    "\n",
    "- `p` is the random variable that models the possible space of Bernoulli parameter $p$s,\n",
    "- `data` is the random variable that models the possible space of data that we could generate.\n",
    "\n",
    "It should be clear that by expressing our model using the language of probability distributions,\n",
    "we gain the ability to concisely write down statistical models.\n",
    "\n",
    "Now, how does data come into play here?\n",
    "\n",
    "Well, what we do is to \"condition\" the model on observe data\n",
    "by passing in data to the random variable. Let's see this in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_tutorial.solutions.inference import coin_flip_data\n",
    "\n",
    "data = coin_flip_data()  # 12 flips, comprising of 8 heads and 4 tails.\n",
    "\n",
    "with pm.Model() as model:\n",
    "    p = pm.Beta(\"p\", alpha=2, beta=2)\n",
    "    data = pm.Bernoulli(\"data\", p=p, observed=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferential Procedure\n",
    "\n",
    "Now we come to the point you've all been waiting for, after all of the basics:\n",
    "How do we perform inference on the key parameter $p$?\n",
    "What should we believe about the parameter $p$,\n",
    "conditioned on our priors?\n",
    "\n",
    "To do this, we're going to follow an inferential procedure\n",
    "that you will see over and over in this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Inference Button! (tm)\n",
    "\n",
    "First off, we're going to hit the inference button below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    trace = pm.sample(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are any warnings that show up, we can ignore them for a moment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What exactly is the inference button doing?\n",
    "\n",
    "Thomas Wiecki, one of the core maintainers of the PyMC3 library,\n",
    "coined the term \"The Inference Button\" to describe the spirit of the PyMC library.\n",
    "\n",
    "Given a probabilistic model, in which we jointly model our parameters and data,\n",
    "the posterior distribution is given by a single equation, Bayes' rule.\n",
    "Calculating the posterior exactly is, in the vast majority of cases, intractable,\n",
    "so we leverage Markov Chain Monte Carlo sampling\n",
    "to help us figure out what the shape of the posterior looks like.\n",
    "(You got a taste of Monte Carlo sampling in the last notebook, right at the end!)\n",
    "\n",
    "PyMC3's `pm.sample(n_steps)` function does the MCMC sampling for us.\n",
    "Along the way, it abstracts away and automates a bunch of steps\n",
    "that we would otherwise have to do on our own.\n",
    "_Are you curious to know more about what happens behind-the-scenes?_\n",
    "_Check out [this introductory explainer that I wrote][essays]!_\n",
    "\n",
    "For readers and learners who can deal with a bit more jargon,\n",
    "here's a bit more detail, written such that the intuition is conveyed\n",
    "(without the math).\n",
    "\n",
    "Firstly, the MCMC sampler gets initialized in an arbitrary region of the posterior distribution space.\n",
    "Then, the sampler \"warms up\" and tries to work its way\n",
    "to the [\"typical set\"][typicalset] of the posterior distribution.\n",
    "Finally, it begins sampling around the typical set,\n",
    "in this way simulating/calculating the posterior distribution.\n",
    "(Warning, the \"typical set\" Wikipedia page linked above contains a ton of math.)\n",
    "\n",
    "[essays]: https://ericmjl.github.io/essays-on-data-science/machine-learning/computational-bayesian-stats/\n",
    "[typicalset]: https://en.wikipedia.org/wiki/Typical_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ArviZ\n",
    "\n",
    "Now that inference has completed, we will obtain a `trace` object, which will contain samples from the posterior distribution.\n",
    "Together, those samples form an approximation of the true posterior.\n",
    "\n",
    "To visualize the posterior, we are going to bring in a companion tool called [ArviZ][arviz],\n",
    "which provides an API that facilitates the visual exploration of Bayesian model outputs.\n",
    "The output of Bayesian inferential protocols is a rich, multi-dimensional data structure,\n",
    "and the ArviZ devs have spent countless hours getting the core data structure right\n",
    "so that the API built around it can be intuitive and helpful.\n",
    "\n",
    "To get started, we have to convert the PyMC3 trace object into an ArviZ `InferenceData` object.\n",
    "\n",
    "[arviz]: https://arviz-devs.github.io/arviz/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "\n",
    "with model:\n",
    "    trace = az.from_pymc3(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now inspect that the trace `InferenceData` object looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to the beautiful HTML representation of the InferenceData object, we can interactively explore it.\n",
    "\n",
    "There are a few things to look at.\n",
    "\n",
    "- `posterior`: Holds the posterior distribution objects. This is what we will be most commonly interacting with.\n",
    "- `log_likelihood`: Holds the log-likelihood calculations that happened at each step of sampling. In the vast majority of applied cases, we will not need to dig into this.\n",
    "- `sample_stats`: Holds information about the MCMC sampler at each sampling step. In the vast majority of applied cases, we will not need to dig into this.\n",
    "- `observed_data`: As per the name. Can be handy when debugging. But as with the previous two, in the vast majority of applied cases, we will not need to dig into this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize your posterior... distribution\n",
    "\n",
    "Now, let's get a feel for the tools that are used for visualization of the posterior distribution.\n",
    "\n",
    "The first visualization tool that we can use to get a handle over our posterior distribution is the `az.plot_posterior` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(trace);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this plot, we can tell that once we condition our model on our data,\n",
    "we believe that our parameter `p` should be centered around 0.62,\n",
    "with 94% of our credibility points being allotted between the values 0.41 and 0.84."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credible vs. Confidence Interval\n",
    "\n",
    "I feel compelled at this point to immediately interject a point here:\n",
    "the 94% of credibility points is the \"highest density interval\",\n",
    "or \"94% credible interval\".\n",
    "This interval has a very direct and simple interpretation:\n",
    "having conditioned our prior belief on data,\n",
    "we believe with 94% probability that the true parameter value\n",
    "lives within this interval range.\n",
    "\n",
    "**The credible interval has nothing to do with the \"confidence interval\"**\n",
    "that you may have learned in classical statistics.\n",
    "When you calculated a confidence interval,\n",
    "the interpretation is that\n",
    "_in the limit of large number of trials $N$_,\n",
    "we will calculate $N$ $\\alpha \\%$ confidence intervals,\n",
    "and $\\alpha \\%$ of them will contain the true value.\n",
    "Does that sound convoluted to you, because of the \"large number of trials\",\n",
    "and \"large number of confidence intervals\"?\n",
    "If so, you're not alone. We think that's convoluted too :)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the chain\n",
    "\n",
    "Whenever we do MCMC sampling, we must always inspect the sampling trace.\n",
    "The sampling trace records every single value that was _accepted_ in MCMC sampling,\n",
    "which gives us the ability to inspect whether the MCMC sampling went well.\n",
    "\n",
    "To inspect the chain, we call upon the `az.plot_trace(trace)` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(trace);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are these plots and how do we interpret them?\n",
    "\n",
    "The left plot shows a kernel density estimate (KDE) of the posterior distribution.\n",
    "The x-axis is the posterior distribution support,\n",
    "while the height is the KDE likelihood estimate.\n",
    "\n",
    "The right plot shows the trace values.\n",
    "The x-axis is sampling step (we did a total of 2000 above),\n",
    "and the y-axis is the sampled value.\n",
    "\n",
    "The left plot is essentially the right plot collapsed across the time axis.\n",
    "\n",
    "As a matter of practice, the trace should look like a \"hairy caterpillar\",\n",
    "and should show no trends (i.e. moving upwards or downwards) anywhere.\n",
    "Trends indicate that the MCMC sampler has not fully \"warmed up\",\n",
    "and is still trying to find its way to the typical set of the posterior distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recapping thus far\n",
    "\n",
    "Up till this point, we have done the following:\n",
    "\n",
    "- Specified a joint probabilistic model for coin flips and its key parameter $p$, the probability of heads, and performed inference,\n",
    "- Visualized the posterior distribution of $p$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Exercises\n",
    "\n",
    "To help you get further familiarity with the basics of PyMC3, here are a few more exercises to work through."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Estimate rate of car crashes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Build the probabilistic model for car crashes in PyMC3\n",
    "\n",
    "- Car crashes, which are integer counts of things that happen with a given rate, generally follow a [Poisson] distribution.\n",
    "- The Poisson distribution has a \"rate\" parameter `mu`, which is only allowed to be positively distributed. The [Exponential] distribution is a pragmatic choice here.\n",
    "\n",
    "[Poisson]: https://docs.pymc.io/api/distributions/discrete.html#pymc3.distributions.discrete.Poisson\n",
    "\n",
    "[Exponential]: https://docs.pymc.io/api/distributions/continuous.html#pymc3.distributions.continuous.Exponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_tutorial.solutions.inference import car_crash_data, car_crash_model_generator\n",
    "\n",
    "data = car_crash_data()\n",
    "\n",
    "# This is one of an infinite set of correct answers.\n",
    "car_crash_model = car_crash_model_generator()\n",
    "\n",
    "# Comment out the line above and specify your model below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Perform inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_tutorial.solutions.inference import model_inference_answer\n",
    "\n",
    "# This is the correct answer\n",
    "trace = model_inference_answer(car_crash_model)\n",
    "\n",
    "# Comment out the line above and write your answer below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Inspect model trace and posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_tutorial.solutions.inference import model_trace_answer\n",
    "\n",
    "model_trace_answer(trace)\n",
    "\n",
    "# Your answer below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_tutorial.solutions.inference import model_posterior_answer\n",
    "\n",
    "model_posterior_answer(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having seen the data, what do we believe about the rate of car crashes per week?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_tutorial.solutions.inference import car_crash_interpretation\n",
    "\n",
    "print(car_crash_interpretation())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Estimate finch beaks mean and variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Build the probabilistic model for finch beaks in PyMC3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_tutorial.solutions.inference import finch_beak_data\n",
    "\n",
    "data = finch_beak_data()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Perform inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_tutorial.solutions.inference import finch_beak_model_generator\n",
    "\n",
    "# This is one of an infinite set of \"correct\" answers:\n",
    "finch_beak_model = finch_beak_model_generator()\n",
    "\n",
    "# Your answer below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the \"correct\" answer:\n",
    "trace = model_inference_answer(finch_beak_model)\n",
    "\n",
    "# Your answer below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Inspect model trace and posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the \"correct\" answer:\n",
    "model_trace_answer(trace)\n",
    "\n",
    "# Your answer below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the \"correct\" answer:\n",
    "model_posterior_answer(trace)\n",
    "\n",
    "# Your answer below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we believe about the:\n",
    "\n",
    "- Expected beak length of a finch, and\n",
    "- Intrinsic variance in beak lengths across all finches\n",
    "\n",
    "having seen the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_tutorial.solutions.inference import finch_beak_interpretation\n",
    "\n",
    "print(finch_beak_interpretation())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook only gave you an introduction to the basics.\n",
    "In particular, you learned:\n",
    "\n",
    "- How to build a probabilistic model with PyMC3.\n",
    "- How to use ArviZ' basic tooling to visualize posterior distributions\n",
    "- Basic wording for reporting on posterior distributions.\n",
    "\n",
    "Believe it or not, things get more complex, and hence more exciting, beyond here!\n",
    "\n",
    "Estimation is an extremely core activity in statistics,\n",
    "and when done in a Bayesian form,\n",
    "we automatically obtain uncertainties that we can _report_.\n",
    "(How we use them is a different story, but stick with us to learn more!)\n",
    "\n",
    "We're now going to continue on to the next chapter,\n",
    "which is on extending the estimation model to support \"multiple groups\"!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_tutorial.solutions import inference\n",
    "\n",
    "inference??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesian-modelling-tutorial",
   "language": "python",
   "name": "bayesian-modelling-tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
