{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import arviz as az\n",
    "from cmdstanpy import CmdStanModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stan supports regression models from simple linear regressions to multilevel generalized linear models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest linear regression model is the following, with a single predictor and a slope and intercept coefficient, and normally distributed noise. This model can be written using standard regression notation as:\n",
    "$$\n",
    "y_n = \\alpha + \\beta x_n + \\epsilon_n\n",
    "\\quad\\text{where}\\quad\n",
    "\\epsilon_n \\sim \\operatorname{normal}(0,\\sigma).\n",
    "$$\n",
    "\n",
    "This is equivalent to the following sampling involving the residual,\n",
    "$$\n",
    "y_n - (\\alpha + \\beta X_n) \\sim \\operatorname{normal}(0,\\sigma),\n",
    "$$\n",
    "and reducing still further, to\n",
    "$$\n",
    "y_n \\sim \\operatorname{normal}(\\alpha + \\beta X_n, \\, \\sigma).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:14:40 - cmdstanpy - INFO - compiling stan file /Users/rehabnaeem/Documents/Coding-Projects/bayesian-analysis/references/Stan-Modelling/stan_models/linear_code_1.stan to exe file /Users/rehabnaeem/Documents/Coding-Projects/bayesian-analysis/references/Stan-Modelling/stan_models/linear_code_1\n",
      "11:14:49 - cmdstanpy - INFO - compiled model executable: /Users/rehabnaeem/Documents/Coding-Projects/bayesian-analysis/references/Stan-Modelling/stan_models/linear_code_1\n"
     ]
    }
   ],
   "source": [
    "linear_code_1 = '''\n",
    "data {\n",
    "    int<lower=0> N;\n",
    "    vector[N] x;\n",
    "    vector[N] y;\n",
    "}\n",
    "\n",
    "parameters {\n",
    "    real alpha;\n",
    "    real beta;\n",
    "    real<lower=0> sigma;\n",
    "}\n",
    "\n",
    "model {\n",
    "    y ~ normal(alpha + beta * x, sigma);\n",
    "}\n",
    "'''\n",
    "\n",
    "stan_file = './stan_models/linear_code_1.stan'\n",
    "\n",
    "with open(stan_file, 'w') as f:\n",
    "    print(linear_code_1, file=f)\n",
    "    \n",
    "linear_1_model = CmdStanModel(stan_file=stan_file, force_compile=True, cpp_options={'STAN_THREADS':'true'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are `N` observations and for each observation, $n \\in N$,  we have predictor `x[n]` and outcome `y[n]`.  The intercept and slope parameters are `alpha` and `beta`. The model assumes a normally\n",
    "distributed noise term with scale `sigma`. This model has improper priors for the two regression coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix notation and vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution statement in the previous model is vectorized, with\n",
    "\n",
    "```stan\n",
    "y ~ normal(alpha + beta * x, sigma);\n",
    "```\n",
    "\n",
    "providing the same model as the unvectorized version,\n",
    "\n",
    "```stan\n",
    "for (n in 1:N) {\n",
    "  y[n] ~ normal(alpha + beta * x[n], sigma);\n",
    "}\n",
    "```\n",
    "\n",
    "In addition to being more concise, the vectorized form is much faster.\n",
    "\n",
    "In general, Stan allows the arguments to distributions such as `normal` to be vectors. If any of the other arguments are vectors or arrays, they have to be the same size. If any of the other arguments is a scalar, it is reused (or broadcasted) for each vector entry.\n",
    "\n",
    "The other reason this works is that Stan's arithmetic operators are overloaded to perform matrix arithmetic on matrices.  In this case, because `x` is of type `vector` and `beta` of type `real`, the expression `beta * x` is of type `vector`. Because Stan supports vectorization, a regression model with more than one predictor can be written directly using matrix notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:14:49 - cmdstanpy - INFO - compiling stan file /Users/rehabnaeem/Documents/Coding-Projects/bayesian-analysis/references/Stan-Modelling/stan_models/linear_code_2.stan to exe file /Users/rehabnaeem/Documents/Coding-Projects/bayesian-analysis/references/Stan-Modelling/stan_models/linear_code_2\n",
      "11:14:58 - cmdstanpy - INFO - compiled model executable: /Users/rehabnaeem/Documents/Coding-Projects/bayesian-analysis/references/Stan-Modelling/stan_models/linear_code_2\n"
     ]
    }
   ],
   "source": [
    "linear_code_2 = '''\n",
    "data {\n",
    "    int<lower=0> N;         // number of data items\n",
    "    int<lower=0> K;         // number of predictors\n",
    "    matrix[N, K] x;         // predictor matrix\n",
    "    vector[N] y;            // outcome vector\n",
    "}\n",
    "\n",
    "parameters {\n",
    "    real alpha;             // intercept\n",
    "    vector[K] beta;         // coefficients for predictors\n",
    "    real<lower=0> sigma;    // error scale\n",
    "}\n",
    "\n",
    "model {\n",
    "    y ~ normal(x * beta + alpha, sigma); // data model\n",
    "}\n",
    "'''\n",
    "\n",
    "stan_file = './stan_models/linear_code_2.stan'\n",
    "\n",
    "with open(stan_file, 'w') as f:\n",
    "    print(linear_code_2, file=f)\n",
    "    \n",
    "linear_2_model = CmdStanModel(stan_file=stan_file, force_compile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The constraint `lower=0` in the declaration of `sigma` constrains the value to be greater than or equal to 0.  With no prior in the model block, the effect is an improper prior on non-negative real numbers.  Although a more informative prior may be added, improper priors are acceptable as long as they lead to proper posteriors.\n",
    "\n",
    "In the model above, `x` is an $N \\times K$ matrix of predictors and `beta` a $K$-vector of coefficients, so `x * beta` is an $N$-vector of predictions, one for each of the $N$ data items. These\n",
    "predictions line up with the outcomes in the $N$-vector `y`, so the entire model may be written using matrix arithmetic as shown.  It would be possible to include a column of ones in the data matrix `x` to\n",
    "remove the `alpha` parameter.\n",
    "\n",
    "The distribution statement in the model above is just a more efficient, vector-based approach to coding the model with a loop, as in the following statistically equivalent model.\n",
    "\n",
    "```stan\n",
    "model {\n",
    "  for (n in 1:N) {\n",
    "    y[n] ~ normal(x[n] * beta, sigma);\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "With Stan's matrix indexing scheme, `x[n]` picks out row `n` of the matrix `x`;  because `beta` is a column vector, the product `x[n] * beta` is a scalar of type `real`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Intercepts as inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the model formulation\n",
    "\n",
    "```stan\n",
    "y ~ normal(x * beta, sigma);\n",
    "```\n",
    "\n",
    "there is no longer an intercept coefficient `alpha`.  Instead, we have assumed that the first column of the input matrix `x` is a column of 1 values.  This way, `beta[1]` plays the role of the intercept.  If the intercept gets a different prior than the slope terms, then it would be clearer to break it out.  It is also slightly more efficient in its explicit form with the intercept variable\n",
    "singled out because there's one fewer multiplications; it should not make that much of a difference to speed, though, so the choice should be based on clarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The QR reparameterization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous example, the linear predictor can be written as $\\eta = x \\beta$, where $\\eta$ is a $N$-vector of predictions, $x$ is a $N \\times K$ matrix, and $\\beta$ is a $K$-vector of coefficients.\n",
    "Presuming $N \\geq K$, we can exploit the fact that any design matrix $x$ can be decomposed using the thin QR decomposition into an orthogonal matrix $Q$ and an upper-triangular matrix $R$, i.e. $x = Q\n",
    "R$.\n",
    "\n",
    "The functions `qr_thin_Q` and `qr_thin_R` implement the thin QR decomposition, which is to be preferred to the fat QR decomposition that would be obtained by using `qr_Q` and `qr_R`, as the latter would more easily run out of memory (see the Stan Functions Reference for more information on the `qr_thin_Q` and `qr_thin_R` functions). In practice, it is best to write $x = Q^\\ast R^\\ast$ where $Q^\\ast = Q * \\sqrt{n - 1}$ and $R^\\ast = \\frac{1}{\\sqrt{n - 1}} R$. Thus, we can equivalently write $\\eta = x \\beta = Q R \\beta = Q^\\ast R^\\ast \\beta$. If we let $\\theta = R^\\ast \\beta$, then we have $\\eta = Q^\\ast \\theta$ and $\\beta = R^{\\ast^{-1}} \\theta$. In that case, the previous Stan program becomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:14:58 - cmdstanpy - INFO - compiling stan file /Users/rehabnaeem/Documents/Coding-Projects/bayesian-analysis/references/Stan-Modelling/stan_models/qr_reparam.stan to exe file /Users/rehabnaeem/Documents/Coding-Projects/bayesian-analysis/references/Stan-Modelling/stan_models/qr_reparam\n",
      "11:15:10 - cmdstanpy - INFO - compiled model executable: /Users/rehabnaeem/Documents/Coding-Projects/bayesian-analysis/references/Stan-Modelling/stan_models/qr_reparam\n"
     ]
    }
   ],
   "source": [
    "qr_reparam = '''\n",
    "data {\n",
    "    int<lower=0> N;         // number of data items\n",
    "    int<lower=0> K;         // number of predictors\n",
    "    matrix[N, K] x;         // predictor matrix\n",
    "    vector[N] y;            // outcome vector\n",
    "}\n",
    "\n",
    "transformed data {\n",
    "    matrix[N, K] Q_ast;\n",
    "    matrix[K, K] R_ast;\n",
    "    matrix[K, K] R_ast_inverse;\n",
    "    // thin and scale the QR decomposition\n",
    "    Q_ast = qr_thin_Q(x) * sqrt(N - 1);\n",
    "    R_ast = qr_thin_R(x) / sqrt(N - 1);\n",
    "    R_ast_inverse = inverse(R_ast);\n",
    "}\n",
    "\n",
    "parameters {\n",
    "    real alpha;             // intercept\n",
    "    vector[K] theta;        // coefficients for Q_ast\n",
    "    real<lower=0> sigma;    // error scale    \n",
    "}\n",
    "\n",
    "model {\n",
    "    y ~ normal(Q_ast * theta + alpha, sigma); // data model\n",
    "}\n",
    "\n",
    "generated quantities {\n",
    "    vector[K] beta;\n",
    "    beta = R_ast_inverse * theta; // coefficients on x\n",
    "}\n",
    "'''\n",
    "\n",
    "stan_file = './stan_models/qr_reparam.stan'\n",
    "\n",
    "with open(stan_file, 'w') as f:\n",
    "    print(qr_reparam, file=f)\n",
    "    \n",
    "qr_reparam_model = CmdStanModel(stan_file=stan_file, force_compile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this Stan program generates equivalent predictions for $y$ and the same posterior distribution for $\\alpha$, $\\beta$, and $\\sigma$ as the previous Stan program, many wonder why the version with this QR reparameterization performs so much better in practice, often both in terms of wall time and in terms of effective sample size. The reasoning is threefold:\n",
    "\n",
    "1. The columns of $Q^\\ast$ are orthogonal whereas the columns of $x$ generally are not. Thus, it is easier for a Markov Chain to move around in $\\theta$-space than in $\\beta$-space.\n",
    "2. The columns of $Q^\\ast$ have the same scale whereas the columns of $x$ generally do not. Thus, a Hamiltonian Monte Carlo algorithm can move around the parameter space with a smaller number of larger steps\n",
    "3. Since the covariance matrix for the columns of $Q^\\ast$ is an identity matrix, $\\theta$ typically has a reasonable scale if the units of $y$ are also reasonable. This also helps HMC move efficiently without compromising numerical accuracy.\n",
    "\n",
    "Consequently, this QR reparameterization is recommended for linear and generalized linear models in Stan whenever $K > 1$ and you do not have an informative prior on the location of $\\beta$. It can also be worthwhile to subtract the mean from each column of $x$ before obtaining the QR decomposition, which does not affect the posterior distribution of $\\theta$ or $\\beta$ but does affect $\\alpha$ and\n",
    "allows you to interpret $\\alpha$ as the expectation of $y$ in a linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robust noise models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard approach to linear regression is to model the noise term $\\epsilon$ as having a normal distribution. From Stan's perspective, there is nothing special about normally distributed noise. For instance, robust regression can be accommodated by giving the noise term a Student-$t$ distribution. To code this in Stan, the distribution distribution is changed to the following.\n",
    "\n",
    "```stan\n",
    "data {\n",
    "  // ...\n",
    "  real<lower=0> nu;\n",
    "}\n",
    "// ...\n",
    "model {\n",
    "  y ~ student_t(nu, alpha + beta * x, sigma);\n",
    "}\n",
    "```\n",
    "\n",
    "The degrees of freedom constant `nu` is specified as data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic and probit regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For binary outcomes, either of the closely related logistic or probit regression models may be used.  These generalized linear models vary only in the link function they use to map linear predictions in $(-\\infty,\\infty)$ to probability values in $(0,1)$.  Their respective link functions, the logistic function and the standard normal cumulative distribution function, are both sigmoid functions (i.e., they are both *S*-shaped).\n",
    "\n",
    "A logistic regression model with one predictor and an intercept is coded as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:15:10 - cmdstanpy - INFO - compiling stan file /Users/rehabnaeem/Documents/Coding-Projects/bayesian-analysis/references/Stan-Modelling/stan_models/logistic_regression.stan to exe file /Users/rehabnaeem/Documents/Coding-Projects/bayesian-analysis/references/Stan-Modelling/stan_models/logistic_regression\n",
      "11:15:18 - cmdstanpy - INFO - compiled model executable: /Users/rehabnaeem/Documents/Coding-Projects/bayesian-analysis/references/Stan-Modelling/stan_models/logistic_regression\n"
     ]
    }
   ],
   "source": [
    "logistic_regression = '''\n",
    "data {\n",
    "    int<lower=0> N;\n",
    "    vector[N] x;\n",
    "    array[N] int<lower=0, upper=1> y;\n",
    "}\n",
    "parameters {\n",
    "    real alpha;\n",
    "    real beta;\n",
    "}\n",
    "model {\n",
    "    y ~ bernoulli_logit(alpha + beta * x);\n",
    "}\n",
    "'''\n",
    "\n",
    "stan_file = './stan_models/logistic_regression.stan'\n",
    "\n",
    "with open(stan_file, 'w') as f:\n",
    "    print(logistic_regression, file=f)\n",
    "\n",
    "logistic_regression_model = CmdStanModel(stan_file=stan_file, force_compile=True, cpp_options={'STAN_THREADS':'true'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The noise parameter is built into the Bernoulli formulation here rather than specified directly.\n",
    "\n",
    "Logistic regression is a kind of generalized linear model with binary outcomes and the log odds (logit) link function, defined by\n",
    "\n",
    "$$\n",
    "\\operatorname{logit}(v) = \\log \\left( \\frac{v}{1-v} \\right).\n",
    "$$\n",
    "\n",
    "The inverse of the link function appears in the model:\n",
    "$$\n",
    "\\operatorname{logit}^{-1}(u) = \\texttt{inv}\\mathtt{\\_}\\texttt{logit}(u) = \\frac{1}{1 + \\exp(-u)}.\n",
    "$$\n",
    "\n",
    "The model formulation above uses the logit-parameterized version of the Bernoulli distribution, which is defined by\n",
    "$$\n",
    "\\texttt{bernoulli}\\mathtt{\\_}\\texttt{logit}\\left(y \\mid \\alpha \\right)\n",
    "=\n",
    "\\texttt{bernoulli}\\left(y \\mid \\operatorname{logit}^{-1}(\\alpha)\\right).\n",
    "$$\n",
    "\n",
    "The formulation is also vectorized in the sense that `alpha` and `beta` are scalars and `x` is a vector, so that `alpha   + beta * x` is a vector. The vectorized formulation is equivalent to the less efficient version\n",
    "\n",
    "```stan\n",
    "for (n in 1:N) {\n",
    "  y[n] ~ bernoulli_logit(alpha + beta * x[n]);\n",
    "}\n",
    "```\n",
    "\n",
    "Expanding out the Bernoulli logit, the model is equivalent to the more explicit, but less efficient and less arithmetically stable\n",
    "\n",
    "\n",
    "```stan\n",
    "for (n in 1:N) {\n",
    "  y[n] ~ bernoulli(inv_logit(alpha + beta * x[n]));\n",
    "}\n",
    "```\n",
    "\n",
    "Other link functions may be used in the same way. For example, probit regression uses the cumulative normal distribution function, which is typically written as\n",
    "\n",
    "$$\n",
    "\\Phi(x) = \\int_{-\\infty}^x \\textsf{normal}\\left(y \\mid 0,1 \\right) \\,\\textrm{d}y.\n",
    "$$\n",
    "\n",
    "The cumulative standard normal distribution function $\\Phi$ is implemented in Stan as the function `Phi`. The probit regression model may be coded in Stan by replacing the logistic model's distribution\n",
    "statement with the following.\n",
    "\n",
    "```stan\n",
    "y[n] ~ bernoulli(Phi(alpha + beta * x[n]));\n",
    "```\n",
    "\n",
    "A fast approximation to the cumulative standard normal distribution function $\\Phi$ is implemented in Stan as the function `Phi_approx`.(The `Phi_approx` function is a rescaled version of the inverse logit function, so while the scale is roughly the same $\\Phi$, the tails do not match.) The approximate probit regression model may be coded with the following.\n",
    "\n",
    "```stan\n",
    "y[n] ~ bernoulli(Phi_approx(alpha + beta * x[n]));\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-logit regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple outcome forms of logistic regression can be coded directly in Stan.  For instance, suppose there are $K$ possible outcomes for each output variable $y_n$. Also suppose that there is a $D$-dimensional vector $x_n$ of predictors for $y_n$.  The multi-logit model with $\\textsf{normal}(0,5)$ priors on the coefficients is coded as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:15:18 - cmdstanpy - INFO - compiling stan file /Users/rehabnaeem/Documents/Coding-Projects/bayesian-analysis/references/Stan-Modelling/stan_models/mutli_logi_reg.stan to exe file /Users/rehabnaeem/Documents/Coding-Projects/bayesian-analysis/references/Stan-Modelling/stan_models/mutli_logi_reg\n",
      "11:15:28 - cmdstanpy - INFO - compiled model executable: /Users/rehabnaeem/Documents/Coding-Projects/bayesian-analysis/references/Stan-Modelling/stan_models/mutli_logi_reg\n"
     ]
    }
   ],
   "source": [
    "mutli_logit_reg = '''\n",
    "data {\n",
    "    int K;\n",
    "    int N;\n",
    "    int D;\n",
    "    array[N] int y;\n",
    "    matrix[N,D] x;\n",
    "}\n",
    "parameters {\n",
    "    matrix[D, K] beta;\n",
    "}\n",
    "model {\n",
    "    matrix[N, K] x_beta = x * beta;\n",
    "    \n",
    "    to_vector(beta) ~ normal(0, 5);\n",
    "    \n",
    "    for (n in 1:N) {\n",
    "        y[n] ~ categorical_logit(x_beta[n]');\n",
    "    }\n",
    "}\n",
    "'''\n",
    "\n",
    "stan_file = './stan_models/mutli_logi_reg.stan'\n",
    "\n",
    "with open(stan_file, 'w') as f:\n",
    "    print(mutli_logit_reg, file=f)\n",
    "    \n",
    "mutli_logit_reg_model = CmdStanModel(stan_file=stan_file, force_compile=True, cpp_options={'STAN_THREADS':'true'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where `x_beta[n]'` is the transpose of `x_beta[n]`. The prior on `beta` is coded in vectorized form. As of Stan 2.18, the categorical-logit distribution is not vectorized for parameter arguments, so the loop is required. The matrix multiplication is pulled out to define a local variable for all of the predictors for efficiency. Like the Bernoulli-logit, the categorical-logit distribution applies softmax internally to convert an arbitrary vector to a simplex,\n",
    "\n",
    "$$\n",
    "\\texttt{categorical}\\mathtt{\\_}\\texttt{logit}\\left(y \\mid \\alpha\\right)\n",
    "=\n",
    "\\texttt{categorical}\\left(y \\mid \\texttt{softmax}(\\alpha)\\right),\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\texttt{softmax}(u) = \\exp(u) / \\operatorname{sum}\\left(\\exp(u)\\right).\n",
    "$$\n",
    "\n",
    "The categorical distribution with log-odds (logit) scaled parameters used above is equivalent to writing\n",
    "\n",
    "```stan\n",
    "y[n] ~ categorical(softmax(x[n] * beta));\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraints on data declarations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data block in the above model is defined without constraints on sizes `K`, `N`, and `D` or on the outcome array `y`. Constraints on data declarations provide error checking at the point data are read (or transformed data are defined), which is before sampling begins. Constraints on data declarations also make the model author's intentions more explicit, which can help with readability. The above model's declarations could be tightened to\n",
    "\n",
    "```stan\n",
    "int<lower=2> K;\n",
    "int<lower=0> N;\n",
    "int<lower=1> D;\n",
    "array[N] int<lower=1, upper=K> y;\n",
    "```\n",
    "\n",
    "These constraints arise because the number of categories, `K`, must be at least two in order for a categorical model to be useful. The number of data items, `N`, can be zero, but not negative; unlike R, Stan's for-loops always move forward, so that a loop extent of `1:N` when `N` is equal to zero ensures the loop's body will not be executed.  The number of predictors, `D`, must be at least one in order for `beta * x[n]` to produce an appropriate argument for `softmax()`.  The categorical outcomes\n",
    "`y[n]` must be between `1` and `K` in order for the discrete sampling to be well defined.\n",
    "\n",
    "Constraints on data declarations are optional. Constraints on parameters declared in the `parameters` block, on the other hand, are *not* optional---they are required to ensure support for all parameter values satisfying their constraints. Constraints on transformed data, transformed parameters, and generated quantities are also optional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifiability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because softmax is invariant under adding a constant to each component of its input, the model is typically only identified if there is a suitable prior on the coefficients.\n",
    "\n",
    "An alternative is to use $(K-1)$-vectors by fixing one of them to be zero. The partially known parameters section discusses how to mix constants and parameters in a vector. In the multi-logit case, the parameter block would be redefined to use $(K - 1)$-vectors\n",
    "\n",
    "```stan\n",
    "parameters {\n",
    "  matrix[D, K - 1] beta_raw;\n",
    "}\n",
    "```\n",
    "\n",
    "and then these are transformed to parameters to use in the model. First, a transformed data block is added before the parameters block to define a vector of zero values,\n",
    "\n",
    "```stan\n",
    "transformed data {\n",
    "  vector[D] zeros = rep_vector(0, D);\n",
    "}\n",
    "```\n",
    "\n",
    "which can then be appended to `beta_raw` to produce the coefficient matrix `beta`,\n",
    "\n",
    "```stan\n",
    "transformed parameters {\n",
    "  matrix[D, K] beta = append_col(beta_raw, zeros);\n",
    "}\n",
    "```\n",
    "\n",
    "The `rep_vector(0, D)` call creates a column vector of size `D` with all entries set to zero. The derived matrix `beta` is then defined to be the result of appending the vector `zeros` as a new column at the end of `beta_raw`;  the vector `zeros` is defined as transformed data so that it doesn't need to be constructed from scratch each time it is used.\n",
    "\n",
    "This is not the same model as using $K$-vectors as parameters, because now the prior only applies to $(K-1)$-vectors. In practice, this will cause the maximum likelihood solutions to be different and also the posteriors to be slightly different when taking priors centered around zero, as is typical for regression coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameterizing centered vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When there are varying effects in a regression, the resulting likelihood is not identified unless further steps are taken. For example, we might have a global intercept $\\alpha$ and then a varying effect $\\beta_k$ for age group $k$ to make a linear predictor $\\alpha + \\beta_k$.  With this predictor, we can add a constant to $\\alpha$ and subtract from each $\\beta_k$ and get exactly the same likelihood.\n",
    "\n",
    "The traditional approach to identifying such a model is to pin the first varing effect to zero, i.e., $\\beta_1 = 0$.  With one of the varying effects fixed, you can no longer add a constant to all of them\n",
    "and the model's likelihood is identified. In addition to the difficulty in specifying such a model in Stan, it is awkward to formulate priors because the other coefficients are all interpreted relative to $\\beta_1$.  \n",
    "\n",
    "In a Bayesian setting, a proper prior on each of the $\\beta$ is enough to identify the model.  Unfortunately, this can lead to inefficiency during sampling as the model is still only weakly identified through the prior---there is a very simple example of the difference in the discussion of collinearity in collinearity section.\n",
    "\n",
    "An alternative identification strategy that allows a symmetric prior is to enforce a sum-to-zero constraint on the varying effects, i.e., $\\sum_{k=1}^K \\beta_k = 0.$\n",
    "\n",
    "A parameter vector constrained to sum to zero may also be used to identify a multi-logit regression parameter vector, or may be used for ability or difficulty parameters (but not both) in an IRT model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Built-in sum-to-zero vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As of Stan 2.36, there is a built in `sum_to_zero_vector` type, which can be used as follows.\n",
    "\n",
    "```stan\n",
    "parameters {\n",
    "  sum_to_zero_vector[K] beta;\n",
    "  // ...\n",
    "}\n",
    "```\n",
    "\n",
    "This produces a vector of size `K` such that `sum(beta) = 0`.  In the unconstrained representation requires only `K - 1` values because the last is determined by the first `K - 1`.  \n",
    "\n",
    "Placing a prior on `beta` in this parameterization, for example,\n",
    "\n",
    "```stan\n",
    "  beta ~ normal(0, 1);\n",
    "```\n",
    "\n",
    "leads to a subtly different posterior than what you would get with the same prior on an unconstrained size-`K` vector. As explained below, the variance is reduced.\n",
    "\n",
    "The sum-to-zero constraint can be implemented naively by setting the last element to the negative sum of the first elements, i.e., $\\beta_K = -\\sum_{k=1}^{K-1} \\beta_k.$ But that leads to high correlation among the $\\beta_k$.\n",
    "\n",
    "The transform used in Stan eliminates these correlations by constructing an orthogonal basis and applying it to the zero-sum-constraint. The *Stan Reference Manual* provides the details in the chapter on transforms.  Although any orthogonal basis can be used, Stan uses the inverse isometric log transform because it is convenient to describe and the transform simplifies to efficient scalar operations rather than more expensive matrix operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Marginal distribution of sum-to-zero components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the Stan forums, Aaron Goodman provided the following code to produce a prior with standard normal marginals on the components of `beta`,\n",
    "\n",
    "```stan\n",
    "model {\n",
    "  beta ~ normal(0, inv(sqrt(1 - inv(K))));\n",
    "  // ...\n",
    "}\n",
    "```\n",
    "\n",
    "The scale component can be multiplied by `sigma` to produce a `normal(0, sigma)` prior marginally.\n",
    "\n",
    "To generate distributions with marginals other than standard normal, the resulting `beta` may be scaled by some factor `sigma` and translated to some new location `mu`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Soft centering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a prior such as $\\beta \\sim \\textsf{normal}(0,\\epsilon)$ for a small $\\epsilon$ will provide a kind of soft centering of a parameter vector $\\beta$ by preferring, all else being equal, that $\\sum_{k=1}^K \\beta_k = 0$.  This approach is only guaranteed to roughly center if $\\beta$ and the elementwise addition $\\beta + c$ for a scalar constant $c$ produce the same likelihood (perhaps by another vector $\\alpha$ being transformed to $\\alpha - c$, as in the IRT models). This is another way of achieving a symmetric prior, though it requires choosing an $\\epsilon$.  If $\\epsilon$ is too large, there won't be a strong enough centering effect and if it is too small, it will add high curvature to the target density and impede sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordered logistic and probit regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordered regression for an outcome $y_n \\in \\{ 1, \\dotsc, k \\}$ with predictors $x_n \\in \\mathbb{R}^D$ is determined by a single coefficient vector $\\beta \\in \\mathbb{R}^D$ along with a sequence of cutpoints $c \\in \\mathbb{R}^{K-1}$ sorted so that $c_d < c_{d+1}$. The discrete output is $k$ if the linear predictor $x_n \\beta$ falls between $c_{k-1}$ and $c_k$, assuming $c_0 = -\\infty$ and $c_K = \\infty$.  The noise term is fixed by the form of regression, with examples for ordered logistic and ordered probit models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ordered logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ordered logistic model can be coded in Stan using the `ordered` data type for the cutpoints and the built-in `ordered_logistic` distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:15:28 - cmdstanpy - INFO - compiling stan file /Users/rehabnaeem/Documents/Coding-Projects/bayesian-analysis/references/Stan-Modelling/stan_models/ordered_logistic_reg.stan to exe file /Users/rehabnaeem/Documents/Coding-Projects/bayesian-analysis/references/Stan-Modelling/stan_models/ordered_logistic_reg\n",
      "11:15:36 - cmdstanpy - INFO - compiled model executable: /Users/rehabnaeem/Documents/Coding-Projects/bayesian-analysis/references/Stan-Modelling/stan_models/ordered_logistic_reg\n"
     ]
    }
   ],
   "source": [
    "ordered_logistic_reg ='''\n",
    "data {\n",
    "    int<lower=2> K;\n",
    "    int<lower=0> N;\n",
    "    int<lower=1> D;\n",
    "    array[N] int<lower=1, upper=K> y;\n",
    "    array[N] row_vector[D] x;\n",
    "}\n",
    "parameters {\n",
    "    vector[D] beta;\n",
    "    ordered[K - 1] c;\n",
    "}\n",
    "model {\n",
    "    for (n in 1:N) {\n",
    "        y[n] ~ ordered_logistic(x[n] * beta, c);\n",
    "    }\n",
    "}\n",
    "'''\n",
    "\n",
    "stan_file = './stan_models/ordered_logistic_reg.stan'\n",
    "\n",
    "with open(stan_file, 'w') as f:\n",
    "    print(ordered_logistic_reg, file=f)\n",
    "\n",
    "ordered_logistic_reg_model = CmdStanModel(stan_file=stan_file, force_compile=True, cpp_options={'STAN_THREADS':'true'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vector of cutpoints `c` is declared as `ordered[K - 1]`, which guarantees that `c[k]` is less than `c[k + 1]`.\n",
    "\n",
    "If the cutpoints were assigned independent priors, the constraint effectively truncates the joint prior to support over points that satisfy the ordering constraint. Luckily, Stan does not need to compute the effect of the constraint on the normalizing term because the probability is needed only up to a proportion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ordered probit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An ordered probit model could be coded in exactly the same way by swapping the cumulative logistic (`inv_logit`) for the cumulative normal (`Phi`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:15:36 - cmdstanpy - INFO - compiling stan file /Users/rehabnaeem/Documents/Coding-Projects/bayesian-analysis/references/Stan-Modelling/stan_models/ordered_probit.stan to exe file /Users/rehabnaeem/Documents/Coding-Projects/bayesian-analysis/references/Stan-Modelling/stan_models/ordered_probit\n",
      "11:15:46 - cmdstanpy - INFO - compiled model executable: /Users/rehabnaeem/Documents/Coding-Projects/bayesian-analysis/references/Stan-Modelling/stan_models/ordered_probit\n"
     ]
    }
   ],
   "source": [
    "ordered_probit = '''\n",
    "data {\n",
    "    int<lower=2> K;\n",
    "    int<lower=0> N;\n",
    "    int<lower=1> D;\n",
    "    array[N] int<lower=1, upper=K> y;\n",
    "    array[N] row_vector[D] x;\n",
    "}\n",
    "parameters {\n",
    "    vector[D] beta;\n",
    "    ordered[K - 1] c;\n",
    "}\n",
    "model {\n",
    "    vector[K] theta;\n",
    "    for (n in 1:N) {\n",
    "        real eta;\n",
    "        eta = x[n] * beta;\n",
    "        theta[1] = 1 - Phi(eta - c[1]);\n",
    "        for (k in 2:(K - 1)) {\n",
    "            theta[k] = Phi(eta - c[k - 1]) - Phi(eta - c[k]);\n",
    "        }\n",
    "        theta[K] = Phi(eta - c[K - 1]);\n",
    "        y[n] ~ categorical(theta);\n",
    "    }\n",
    "}\n",
    "'''\n",
    "\n",
    "stan_file = './stan_models/ordered_probit.stan'\n",
    "\n",
    "with open(stan_file, 'w') as f:\n",
    "    print(ordered_probit, file=f)\n",
    "\n",
    "ordered_probit_model = CmdStanModel(stan_file=stan_file, force_compile=True, cpp_options={'STAN_THREADS':'true'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic model could also be coded this way by replacing `Phi` with `inv_logit`, though the built-in encoding based on the softmax transform is more efficient and more numerically stable. A small efficiency gain could be achieved by computing the values `Phi(eta - c[k])` once and storing them for re-use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
