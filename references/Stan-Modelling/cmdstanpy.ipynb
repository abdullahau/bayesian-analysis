{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import arviz as az\n",
    "from cmdstanpy import CmdStanModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stan supports regression models from simple linear regressions to multilevel generalized linear models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest linear regression model is the following, with a single predictor and a slope and intercept coefficient, and normally distributed noise. This model can be written using standard regression notation as:\n",
    "$$\n",
    "y_n = \\alpha + \\beta x_n + \\epsilon_n\n",
    "\\quad\\text{where}\\quad\n",
    "\\epsilon_n \\sim \\operatorname{normal}(0,\\sigma).\n",
    "$$\n",
    "\n",
    "This is equivalent to the following sampling involving the residual,\n",
    "$$\n",
    "y_n - (\\alpha + \\beta X_n) \\sim \\operatorname{normal}(0,\\sigma),\n",
    "$$\n",
    "and reducing still further, to\n",
    "$$\n",
    "y_n \\sim \\operatorname{normal}(\\alpha + \\beta X_n, \\, \\sigma).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:32:25 - cmdstanpy - INFO - compiling stan file /Users/rehabnaeem/Documents/Coding-Projects/bayesian-analysis/references/Stan-Modelling/stan_models/linear_code_1.stan to exe file /Users/rehabnaeem/Documents/Coding-Projects/bayesian-analysis/references/Stan-Modelling/stan_models/linear_code_1\n",
      "16:32:35 - cmdstanpy - INFO - compiled model executable: /Users/rehabnaeem/Documents/Coding-Projects/bayesian-analysis/references/Stan-Modelling/stan_models/linear_code_1\n"
     ]
    }
   ],
   "source": [
    "linear_code_1 = '''\n",
    "data {\n",
    "    int<lower=0> N;\n",
    "    vector[N] x;\n",
    "    vector[N] y;\n",
    "}\n",
    "\n",
    "parameters {\n",
    "    real alpha;\n",
    "    real beta;\n",
    "    real<lower=0> sigma;\n",
    "}\n",
    "\n",
    "model {\n",
    "    y ~ normal(alpha + beta * x, sigma);\n",
    "}\n",
    "'''\n",
    "\n",
    "stan_file = './stan_models/linear_code_1.stan'\n",
    "\n",
    "with open(stan_file, 'w') as f:\n",
    "    print(linear_code_1, file=f)\n",
    "    \n",
    "linear_1_model = CmdStanModel(stan_file=stan_file, force_compile=True, cpp_options={'STAN_THREADS':'true'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are `N` observations and for each observation, $n \\in N$,  we have predictor `x[n]` and outcome `y[n]`.  The intercept and slope parameters are `alpha` and `beta`. The model assumes a normally\n",
    "distributed noise term with scale `sigma`. This model has improper priors for the two regression coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix notation and vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution statement in the previous model is vectorized, with\n",
    "\n",
    "```stan\n",
    "y ~ normal(alpha + beta * x, sigma);\n",
    "```\n",
    "\n",
    "providing the same model as the unvectorized version,\n",
    "\n",
    "```stan\n",
    "for (n in 1:N) {\n",
    "  y[n] ~ normal(alpha + beta * x[n], sigma);\n",
    "}\n",
    "```\n",
    "\n",
    "In addition to being more concise, the vectorized form is much faster.\n",
    "\n",
    "In general, Stan allows the arguments to distributions such as `normal` to be vectors. If any of the other arguments are vectors or arrays, they have to be the same size. If any of the other arguments is a scalar, it is reused (or broadcasted) for each vector entry.\n",
    "\n",
    "The other reason this works is that Stan's arithmetic operators are overloaded to perform matrix arithmetic on matrices.  In this case, because `x` is of type `vector` and `beta` of type `real`, the expression `beta * x` is of type `vector`. Because Stan supports vectorization, a regression model with more than one predictor can be written directly using matrix notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:28:12 - cmdstanpy - INFO - compiling stan file /Users/rehabnaeem/Documents/Coding-Projects/bayesian-analysis/references/Stan-Modelling/stan_models/linear_code_2.stan to exe file /Users/rehabnaeem/Documents/Coding-Projects/bayesian-analysis/references/Stan-Modelling/stan_models/linear_code_2\n",
      "16:28:21 - cmdstanpy - INFO - compiled model executable: /Users/rehabnaeem/Documents/Coding-Projects/bayesian-analysis/references/Stan-Modelling/stan_models/linear_code_2\n"
     ]
    }
   ],
   "source": [
    "linear_code_2 = '''\n",
    "data {\n",
    "    int<lower=0> N;         // number of data items\n",
    "    int<lower=0> K;         // number of predictors\n",
    "    matrix[N, K] x;         // predictor matrix\n",
    "    vector[N] y;            // outcome vector\n",
    "}\n",
    "\n",
    "parameters {\n",
    "    real alpha;             // intercept\n",
    "    vector[K] beta;         // coefficients for predictors\n",
    "    real<lower=0> sigma;    // error scale\n",
    "}\n",
    "\n",
    "model {\n",
    "    y ~ normal(x * beta + alpha, sigma); // data model\n",
    "}\n",
    "'''\n",
    "\n",
    "stan_file = './stan_models/linear_code_2.stan'\n",
    "\n",
    "with open(stan_file, 'w') as f:\n",
    "    print(linear_code_2, file=f)\n",
    "    \n",
    "linear_2_model = CmdStanModel(stan_file=stan_file, force_compile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The constraint `lower=0` in the declaration of `sigma` constrains the value to be greater than or equal to 0.  With no prior in the model block, the effect is an improper prior on non-negative real numbers.  Although a more informative prior may be added, improper priors are acceptable as long as they lead to proper posteriors.\n",
    "\n",
    "In the model above, `x` is an $N \\times K$ matrix of predictors and `beta` a $K$-vector of coefficients, so `x * beta` is an $N$-vector of predictions, one for each of the $N$ data items. These\n",
    "predictions line up with the outcomes in the $N$-vector `y`, so the entire model may be written using matrix arithmetic as shown.  It would be possible to include a column of ones in the data matrix `x` to\n",
    "remove the `alpha` parameter.\n",
    "\n",
    "The distribution statement in the model above is just a more efficient, vector-based approach to coding the model with a loop, as in the following statistically equivalent model.\n",
    "\n",
    "```stan\n",
    "model {\n",
    "  for (n in 1:N) {\n",
    "    y[n] ~ normal(x[n] * beta, sigma);\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "With Stan's matrix indexing scheme, `x[n]` picks out row `n` of the matrix `x`;  because `beta` is a column vector, the product `x[n] * beta` is a scalar of type `real`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Intercepts as inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the model formulation\n",
    "\n",
    "```stan\n",
    "y ~ normal(x * beta, sigma);\n",
    "```\n",
    "\n",
    "there is no longer an intercept coefficient `alpha`.  Instead, we have assumed that the first column of the input matrix `x` is a column of 1 values.  This way, `beta[1]` plays the role of the intercept.  If the intercept gets a different prior than the slope terms, then it would be clearer to break it out.  It is also slightly more efficient in its explicit form with the intercept variable\n",
    "singled out because there's one fewer multiplications; it should not make that much of a difference to speed, though, so the choice should be based on clarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The QR reparameterization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous example, the linear predictor can be written as $\\eta = x \\beta$, where $\\eta$ is a $N$-vector of predictions, $x$ is a $N \\times K$ matrix, and $\\beta$ is a $K$-vector of coefficients.\n",
    "Presuming $N \\geq K$, we can exploit the fact that any design matrix $x$ can be decomposed using the thin QR decomposition into an orthogonal matrix $Q$ and an upper-triangular matrix $R$, i.e. $x = Q\n",
    "R$.\n",
    "\n",
    "The functions `qr_thin_Q` and `qr_thin_R` implement the thin QR decomposition, which is to be preferred to the fat QR decomposition that would be obtained by using `qr_Q` and `qr_R`, as the latter would more easily run out of memory (see the Stan Functions Reference for more information on the `qr_thin_Q` and `qr_thin_R` functions). In practice, it is best to write $x = Q^\\ast R^\\ast$ where $Q^\\ast = Q * \\sqrt{n - 1}$ and $R^\\ast = \\frac{1}{\\sqrt{n - 1}} R$. Thus, we can equivalently write $\\eta = x \\beta = Q R \\beta = Q^\\ast R^\\ast \\beta$. If we let $\\theta = R^\\ast \\beta$, then we have $\\eta = Q^\\ast \\theta$ and $\\beta = R^{\\ast^{-1}} \\theta$. In that case, the previous Stan program becomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:20:59 - cmdstanpy - INFO - compiling stan file /Users/rehabnaeem/Documents/Coding-Projects/bayesian-analysis/references/Stan-Modelling/stan_models/qr_reparam.stan to exe file /Users/rehabnaeem/Documents/Coding-Projects/bayesian-analysis/references/Stan-Modelling/stan_models/qr_reparam\n",
      "17:21:10 - cmdstanpy - INFO - compiled model executable: /Users/rehabnaeem/Documents/Coding-Projects/bayesian-analysis/references/Stan-Modelling/stan_models/qr_reparam\n"
     ]
    }
   ],
   "source": [
    "qr_reparam = '''\n",
    "data {\n",
    "    int<lower=0> N;         // number of data items\n",
    "    int<lower=0> K;         // number of predictors\n",
    "    matrix[N, K] x;         // predictor matrix\n",
    "    vector[N] y;            // outcome vector\n",
    "}\n",
    "\n",
    "transformed data {\n",
    "    matrix[N, K] Q_ast;\n",
    "    matrix[K, K] R_ast;\n",
    "    matrix[K, K] R_ast_inverse;\n",
    "    // thin and scale the QR decomposition\n",
    "    Q_ast = qr_thin_Q(x) * sqrt(N - 1);\n",
    "    R_ast = qr_thin_R(x) / sqrt(N - 1);\n",
    "    R_ast_inverse = inverse(R_ast);\n",
    "}\n",
    "\n",
    "parameters {\n",
    "    real alpha;             // intercept\n",
    "    vector[K] theta;        // coefficients for Q_ast\n",
    "    real<lower=0> sigma;    // error scale    \n",
    "}\n",
    "\n",
    "model {\n",
    "    y ~ normal(Q_ast * theta + alpha, sigma); // data model\n",
    "}\n",
    "\n",
    "generated quantities {\n",
    "    vector[K] beta;\n",
    "    beta = R_ast_inverse * theta; // coefficients on x\n",
    "}\n",
    "'''\n",
    "\n",
    "stan_file = './stan_models/qr_reparam.stan'\n",
    "\n",
    "with open(stan_file, 'w') as f:\n",
    "    print(qr_reparam, file=f)\n",
    "    \n",
    "qr_reparam_model = CmdStanModel(stan_file=stan_file, force_compile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this Stan program generates equivalent predictions for $y$ and the same posterior distribution for $\\alpha$, $\\beta$, and $\\sigma$ as the previous Stan program, many wonder why the version with this QR reparameterization performs so much better in practice, often both in terms of wall time and in terms of effective sample size. The reasoning is threefold:\n",
    "\n",
    "1. The columns of $Q^\\ast$ are orthogonal whereas the columns of $x$ generally are not. Thus, it is easier for a Markov Chain to move around in $\\theta$-space than in $\\beta$-space.\n",
    "2. The columns of $Q^\\ast$ have the same scale whereas the columns of $x$ generally do not. Thus, a Hamiltonian Monte Carlo algorithm can move around the parameter space with a smaller number of larger steps\n",
    "3. Since the covariance matrix for the columns of $Q^\\ast$ is an identity matrix, $\\theta$ typically has a reasonable scale if the units of $y$ are also reasonable. This also helps HMC move efficiently without compromising numerical accuracy.\n",
    "\n",
    "Consequently, this QR reparameterization is recommended for linear and generalized linear models in Stan whenever $K > 1$ and you do not have an informative prior on the location of $\\beta$. It can also be worthwhile to subtract the mean from each column of $x$ before obtaining the QR decomposition, which does not affect the posterior distribution of $\\theta$ or $\\beta$ but does affect $\\alpha$ and\n",
    "allows you to interpret $\\alpha$ as the expectation of $y$ in a linear model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
